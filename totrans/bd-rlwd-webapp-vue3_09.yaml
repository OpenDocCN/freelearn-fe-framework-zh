- en: '9'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Experimental Object Recognition with TensorFlow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It’s time for something a bit more experimental. As we’ve seen, **artificial
    intelligence** (**AI**) offers lots of new opportunities to explore when writing
    code assisted by AI as well as building solutions that are powered by AI. In this
    chapter, we’ll take a look at **TensorFlow**. Google developed and published TensorFlow
    under an open source license. It enables developers to use and train machine learning
    models for different sorts of applications. You can find a curated list of demos
    on the TensorFlow website: [https://www.tensorflow.org/js/demos](https://www.tensorflow.org/js/demos).'
  prefs: []
  type: TYPE_NORMAL
- en: We’re going to apply a small part of the libraries that Google has published
    by leveraging the default published model for object recognition.
  prefs: []
  type: TYPE_NORMAL
- en: First, we’ll build a small example prototype to discover some of the capabilities.
    Then, we’ll apply our newly acquired knowledge to build something experimental
    and fun. It’s another game, where you have to track down real-life objects using
    the camera in your browser!
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’ll cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Prototyping a concept to identify capabilities and limitations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Leveraging multiple external APIs to build a multimedia app
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the browser’s native **Camera**, **Text to Speech**, and **Media** **Stream**
    APIs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The example we’ll be building has touch points with previous chapters and offers
    some potential opportunities for you to customize the application for your personal
    use case. I challenge you to create something unique here, based on the final
    code solution – maybe even a native app using what you learned about Quasar in
    [*Chapter 7*](B19563_07.xhtml#_idTextAnchor204)!
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We’ll build the main app on the **Vuetify** framework ([https://vuetifyjs.com/en/](https://vuetifyjs.com/en/))
    and **Pinia** ([https://pinia.vuejs.org/](https://pinia.vuejs.org/)) to manage
    the state. As stated previously, we’ll leverage various **TensorFlow** libraries
    ([https://www.tensorflow.org/js/](https://www.tensorflow.org/js/)) to incorporate
    some intelligence into our app.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find the complete code for this chapter here: [https://github.com/PacktPublishing/Building-Real-world-Web-Applications-with-Vue.js-3/tree/main/09.tensorflow.](https://github.com/PacktPublishing/Building-Real-world-Web-Applications-with-Vue.js-3/tree/main/09.tensorflow
    )'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s get started with a prototype app!
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to TensorFlow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When I need to research a new framework or technique, I find it very helpful
    to create a small application for it so that I can test it in complete isolation.
    We’re going to apply the same approach with TensorFlow. The original idea is that
    we create an app using the object recognition library ([https://github.com/tensorflow/tfjs-models/tree/master/coco-ssd](https://github.com/tensorflow/tfjs-models/tree/master/coco-ssd))
    and apply the model to images from the camera on our device.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the project
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s use a familiar framework to quickly build some boilerplate for our new
    project. We’ll use the Vuetify CLI to create a new project for us:'
  prefs: []
  type: TYPE_NORMAL
- en: Run `npm create vuetify@3.0.0` in the command-line interface.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose `vue-tensorflow` as the project’s name.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the `Essentials (Vuetify, VueRouter,` `Pinia)` installation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select `TypeScript` using the arrow keys.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select `npm` to install the dependencies.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you navigate to the new project folder, you can run the local development
    server with `npm run dev`. The result should look very familiar to us since we’ve
    done this a few times now (see [*Chapter 5*](B19563_05.xhtml#_idTextAnchor130),
    *Figure 5**.1*).
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we’ll install the dependencies for using TensorFlow. The first two dependencies
    we’ll install will help us in sourcing the CPU and WebGL to help with calculations
    in the algorithm. From the terminal, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We’ll use a pretrained model to help us with object recognition. **Coco SSD**
    ([https://github.com/tensorflow/tfjs-models/tree/master/coco-ssd](https://github.com/tensorflow/tfjs-models/tree/master/coco-ssd))
    can be used to identify multiple objects in a single image. We can install the
    model as a dependency of our project by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: That’s all we need for now!
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: One of the limitations we’ll be running into is that a pretrained model is trained
    to recognize a limited set of classes (classes refer to a classification of an
    object in a category). We only have access to some 80 different classes. We’re
    going to have to work with this limitation.
  prefs: []
  type: TYPE_NORMAL
- en: 'To prepare the object recognition for future developments, we’ll create a store
    to wrap the features. Since we selected Pinia during installation, an empty store
    has been initialized on the project. We’ll create a new file called `objects.ts`
    in the `./store` folder: [https://github.com/PacktPublishing/Building-Real-world-Web-Applications-with-Vue.js-3/blob/main/09.tensorflow/.notes/9.1-object.ts](https://github.com/PacktPublishing/Building-Real-world-Web-Applications-with-Vue.js-3/blob/main/09.tensorflow/.notes/9.1-object.ts).'
  prefs: []
  type: TYPE_NORMAL
- en: We set some properties to track the status of the model. Bear in mind that it
    can take some time for a model to load, so we have to make sure that we inform
    the user so that they have a decent user experience. On store initialization,
    we must immediately call the `loadModel()` function, which loads the model on
    the store (*lines 14, 32–39*), for easy access throughout the app.
  prefs: []
  type: TYPE_NORMAL
- en: We’ve also added and exposed a `detect` function (*lines 22–30*). The function
    takes in an image and runs the image through the model. The result is an array
    of detected items with a certainty per item.
  prefs: []
  type: TYPE_NORMAL
- en: For now, this is enough for us to start working on an implementation. Now, let’s
    build an interface for our prototype.
  prefs: []
  type: TYPE_NORMAL
- en: Performing and displaying a status check
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'It would be very valuable to see what the app is doing, especially since the
    first load of the model can take some time. We’ll build a nice visual component
    to list the status of loading the model. Let’s create a component called `StatusCheck.vue`
    in the `./``components` folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This component is simply listing the status from the store in a nicely formatted
    way. It also emits the `model-loaded` event when the model is loaded so that we
    can pick up on the event. Let’s have the model loading status show up in our app.
    We can delete the `HelloWorld.vue` file from the `./components` folder and replace
    the contents of `./view/Home.vue` with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can run our app for the first time. You will notice that it takes a
    while to load at first, but after some time, you should see something similar
    to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.1 – Visualizing the status of the model](img/B19563_09_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.1 – Visualizing the status of the model
  prefs: []
  type: TYPE_NORMAL
- en: Now that our model has been loaded, we can use it! We’ll build an image upload
    field and have the model analyze the contents of the image.
  prefs: []
  type: TYPE_NORMAL
- en: Selecting an image
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We’ll begin by creating a new component in the `components` folder. We’ll call
    it `ImageDetect.vue` and start with the following contents:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: As shown in the template, we’re moving some template logic to this file. We’re
    using the `<StatusCheck />` component with the `@model-loaded` event to determine
    whether the image detection controls should be visible or active.
  prefs: []
  type: TYPE_NORMAL
- en: In the scripts, we first set some of the variables we need to track the images
    that are being selected in the browser. Once the user changes the contents of
    the file, we can load the image in the browser’s memory so that we can display
    it in the placeholder.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll go to `./views/Home.vue` and replace its contents to load this new component:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we have a feature that provides images and we have a store that should
    be able to detect objects on images. Let’s start to connect those by adding the
    store references to the `script` tag and adding a button to trigger the detection:
    [https://github.com/PacktPublishing/Building-Real-world-Web-Applications-with-Vue.js-3/blob/main/09.tensorflow/.notes/9.2-ImageDetect.vue](https://github.com/PacktPublishing/Building-Real-world-Web-Applications-with-Vue.js-3/blob/main/09.tensorflow/.notes/9.2-ImageDetect.vue).'
  prefs: []
  type: TYPE_NORMAL
- en: As shown on *line 7*, we’re ready to display detected objects.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'In terms of limitations, I mentioned that the model is capable of identifying
    several objects. The list can be found here: [https://github.com/tensorflow/tfjs-models/blob/master/coco-ssd/src/classes.ts](https://github.com/tensorflow/tfjs-models/blob/master/coco-ssd/src/classes.ts).'
  prefs: []
  type: TYPE_NORMAL
- en: I recommend trying this feature out with images of a person, or one of the listed
    classes.
  prefs: []
  type: TYPE_NORMAL
- en: 'After applying the detection, you should end up with something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.2 – Object recognition based on an uploaded image](img/B19563_09_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.2 – Object recognition based on an uploaded image
  prefs: []
  type: TYPE_NORMAL
- en: 'This is already pretty interesting, but let’s see if we can apply some more
    features. First, we’ll look into formatting the results nicely: [https://github.com/PacktPublishing/Building-Real-world-Web-Applications-with-Vue.js-3/blob/main/09.tensorflow/.notes/9.3-ImageDetect.vue](https://github.com/PacktPublishing/Building-Real-world-Web-Applications-with-Vue.js-3/blob/main/09.tensorflow/.notes/9.3-ImageDetect.vue).'
  prefs: []
  type: TYPE_NORMAL
- en: As shown on *lines 12–22*, we’ve added a nicely formatted list of detected items.
    We use the `roundNumber` function (*lines 18, 65–67*) to round the percentages.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s explore adding an additional feature and see if we can give our application
    a voice by exploring the Speech Synthesis API.
  prefs: []
  type: TYPE_NORMAL
- en: Adding a voice to the app
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since we’re looking at non-traditional input for our app (using images rather
    than a mouse and keyboard), it’s interesting to explore different ways of presenting
    information as well. Modern browsers have a built-in feature for converting **Text
    To Speech** (**TTS**) called **SpeechSynthesisUtterance** ([https://developer.mozilla.org/en-US/docs/Web/API/SpeechSynthesisUtterance](https://developer.mozilla.org/en-US/docs/Web/API/SpeechSynthesisUtterance)).
    Let’s work on an addition for our prototype where we can explore this.
  prefs: []
  type: TYPE_NORMAL
- en: 'This API is pretty straightforward to set up. We will start by creating a new
    component called `TextToSpeech.vue` in the `./components` folder that will accept
    the text as a prop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: In the `tts` function, we can see how we can access the API and send a message
    to speak. Since we want to disable the button while speech is active, we’re keeping
    track of the `onstart` and `onend` callback functions and updating the `isSpeaking`
    variable accordingly. We’re playing around a bit with the `rate` and `pitch` settings
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: There are some more options we have when configuring `SpeechSynthesisUtterance`
    as we can read in the documentation. However, unfortunately, I’ve found that there
    are some limits. There are some mismatches between browsers and the support of
    certain languages is not very stable or usable. The `TextToSpeech.vue` component,
    however, should work in our application, so let’s add speech to our app!
  prefs: []
  type: TYPE_NORMAL
- en: 'With the component stored, we’ll add it to the template of `ImageDetect.vue`
    (don’t forget to import the component!):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from the template, we need to provide the component with `speech`.
    Let’s have a look at the code: [https://github.com/PacktPublishing/Building-Real-world-Web-Applications-with-Vue.js-3/blob/main/09.tensorflow/.notes/9.4-ImageDetect.vue](https://github.com/PacktPublishing/Building-Real-world-Web-Applications-with-Vue.js-3/blob/main/09.tensorflow/.notes/9.4-ImageDetect.vue).'
  prefs: []
  type: TYPE_NORMAL
- en: We’ve added a couple of helpers here. We want the speech to only name unique
    classes, so we’re adding a computed variable called `uniqueObjects` that filters
    all duplicate entries (*lines 71–75*). The computed `speech` value (*lines 77–85*)
    takes in that list and joins them using the Intl API, which we also used in [*Chapter
    4*](B19563_04.xhtml#_idTextAnchor092)! The output is what we can send safely to
    the `<TextToSpeech />` component.
  prefs: []
  type: TYPE_NORMAL
- en: Try it out if you want! Our prototype is functional, which is all we need to
    be able to learn from it.
  prefs: []
  type: TYPE_NORMAL
- en: Learning from the prototype
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'So, with this micro app in place, we can experiment a bit. I was running into
    two major problems:'
  prefs: []
  type: TYPE_NORMAL
- en: Object recognition works, but it is very limited to the classes from the pretrained
    model. Providing a self-trained model should be possible, but it is a bit too
    complex to handle in the scope of this topic.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The TTS capabilities between browsers are not very stable or reliable, especially
    between languages.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: My initial idea was to create an app that would use the camera feed to point
    out objects that we could then learn to translate. With those two limitations,
    it’s not going to be feasible to build. Luckily, we can still have some fun with
    the reliable features, without needing to modify the model.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s build a little game where we need to collect objects. We can have the
    existing classes list and prune it a bit so that it fits our use case. Let’s go
    on a scavenger hunt!
  prefs: []
  type: TYPE_NORMAL
- en: Scavenge Hunter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we’ll build a small app that can run on a web browser, preferably
    on a mobile phone. With *Scavenge Hunter*, the goal is to collect certain items
    from a list. We can use parts of the classes list to control the items our user
    needs to collect and in that case, we’re sure to be able to detect those objects!
  prefs: []
  type: TYPE_NORMAL
- en: Once an object has been detected, we’re going to add a score based on the find
    and certainty of the model. Since we can’t guarantee that objects are being recognized
    properly, we should also be able to skip an assignment. Instead of uploading an
    image, we’re going to use the camera stream!
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the project
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can continue using the prototype we built or create a new project if we’d
    like. In the case of the latter, the dependencies and store are required, so we’d
    need to repeat the relevant steps provided in the *Setting up the project* and
    *Performing and displaying a status* *check* sections.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see how we can turn the foundation of our prototype into a little game,
    shall we?
  prefs: []
  type: TYPE_NORMAL
- en: Generic changes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We’re going to start with a configuration file. We need to create this file
    in the root of the project as `config.ts`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: It can be very helpful to have this sort of configuration files in a central
    place so that we don’t have to spend time hunting settings down in individual
    files. Feel free to modify the game configuration values in the `config.ts` file!
  prefs: []
  type: TYPE_NORMAL
- en: Let’s also open the `./index.html` template so that we can update the title
    tag to the new project’s name – that is, *Scavenge Hunter*.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll also create two new view files in the `./views` folder. It’s okay to
    just paste some placeholder content here, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'We need a view for the finding state, called `Find.vue`, and one for the end
    of a game, called `End.vue`. We’ll add the contents later, in the *Building the
    finish screen* and *Skipping to the end* sections. With the views in place, we
    can update the `./router/index.ts` file with the following contents: [https://github.com/PacktPublishing/Building-Real-world-Web-Applications-with-Vue.js-3/blob/main/09.tensorflow/.notes/9.5-index.ts](https://github.com/PacktPublishing/Building-Real-world-Web-Applications-with-Vue.js-3/blob/main/09.tensorflow/.notes/9.5-index.ts).'
  prefs: []
  type: TYPE_NORMAL
- en: 'We’re also going to simplify the interface a bit more. In the `./layouts/default`
    folder, delete the `AppBar.vue` and `View.vue` files. In the `Default.vue` file,
    replace its contents with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Now, we should be able to run the app, but there’s not much new to do at the
    moment. Let’s add some core features via Pinia stores.
  prefs: []
  type: TYPE_NORMAL
- en: Additional stores
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'I usually start by designing and setting up the stores since they usually act
    as a central source of information and methods. First, we’re going to replace
    the contents of the `./store/app.ts` file with contents that are very similar
    to those from [*Chapter* *6*](B19563_06.xhtml#_idTextAnchor162): [https://github.com/PacktPublishing/Building-Real-world-Web-Applications-with-Vue.js-3/blob/main/09.tensorflow/.notes/9.6-app.ts](https://github.com/PacktPublishing/Building-Real-world-Web-Applications-with-Vue.js-3/blob/main/09.tensorflow/.notes/9.6-app.ts).'
  prefs: []
  type: TYPE_NORMAL
- en: It’s a trimmed-down version of the app store we used to build our fitness tracker,
    but we’ve removed all the unnecessary features.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we’re dealing with a predefined list of classes, we’re going to add those
    to the `object.ts` store as an additional value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: I’ve not added all of the categories and instead selected the classes that we
    could find in someone’s home. You can change this to what you think is reasonable
    to have on hand (especially for testing purposes).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s also introduce some game mechanics by adding a `./store/game.ts` store
    file: [https://github.com/PacktPublishing/Building-Real-world-Web-Applications-with-Vue.js-3/blob/main/09.tensorflow/.notes/9.7-game.ts](https://github.com/PacktPublishing/Building-Real-world-Web-Applications-with-Vue.js-3/blob/main/09.tensorflow/.notes/9.7-game.ts).'
  prefs: []
  type: TYPE_NORMAL
- en: This store contains references to the rounds that are being played and which
    are being skipped (*lines 19–23*), keeps track of the score (*line 23*), and helps
    in selecting a category from the list of objects we’ve defined in the `object`
    store. In particular, `getNewCategory` (*lines 28–45*) is interesting since it
    pulls a randomized category from the `objects` collection while making sure it’s
    always a unique new category.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a final step in this section, we’ll replace the contents of the `./App.vue`
    file: [https://github.com/PacktPublishing/Building-Real-world-Web-Applications-with-Vue.js-3/blob/main/09.tensorflow/.notes/9.8-App.vue](https://github.com/PacktPublishing/Building-Real-world-Web-Applications-with-Vue.js-3/blob/main/09.tensorflow/.notes/9.8-App.vue).'
  prefs: []
  type: TYPE_NORMAL
- en: This connects the app store’s capabilities to the interface. Now, we can continue
    building up our little game!
  prefs: []
  type: TYPE_NORMAL
- en: Starting a new game
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We’ll start by creating a button that triggers the conditions for a new game.
    In the `components` folder, we’ll create a `StartGame.vue` component, which is
    nothing more than a button with some actions on it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, we’re relying on the store to tell the button whether the button
    should be disabled. We trigger a new game by calling the `reset()` function of
    `gameStore` and calling a `navigateToPage` function on `appStore`. Now, we should
    be able to place this button component on the `Home.vue` view. Let’s update that
    view completely with the following contents:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'If you’re running the app now, you’ll notice that it’s impossible to start
    the game. Since we want to use the user’s camera feed, we need to request access.
    We’re going to expand the `StatusCheck.vue` file to also make sure we have access
    to a camera. We can use a composable from the `VueUse` library for this. So, from
    the terminal, let’s install the `VueUse` package with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: With this dependency, we can update the `StatusCheck.vue` file. The changes
    to that component are quite extensive, so use the source from [https://github.com/PacktPublishing/Building-Real-world-Web-Applications-with-Vue.js-3/blob/main/09.tensorflow/.notes/9.9-StatusCheck.vue](https://github.com/PacktPublishing/Building-Real-world-Web-Applications-with-Vue.js-3/blob/main/09.tensorflow/.notes/9.9-StatusCheck.vue).
  prefs: []
  type: TYPE_NORMAL
- en: Apart from some additional formatting on our model loading status and some template
    changes that show the actual status, most changes take place in the script. The
    `usePermission` composable returns a reactive property that lets us know if the
    user has granted access to use the camera. If both the model is loaded and the
    user has granted camera access, the game can start (*lines 61–65*). As you can
    see, we’re using the `watch` function on multiple values by providing them as
    arrays (line 61) to the `watch` function.
  prefs: []
  type: TYPE_NORMAL
- en: In the `onMounted` hook (*lines 67–81*), we manually attempt to request a video
    stream. Once the stream starts, we immediately close it down since we don’t need
    the stream, just the permission. The permission is persistent throughout our visit.
  prefs: []
  type: TYPE_NORMAL
- en: Building the finish screen
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before we dive into the image streams and object-hunting aspects, we’ll build
    the final screen. We’ll create a component in the `./components` folder to display
    the result of a game called `ScoreCard.vue`: [https://github.com/PacktPublishing/Building-Real-world-Web-Applications-with-Vue.js-3/blob/main/09.tensorflow/.notes/9.10-ScoreCard.vue](https://github.com/PacktPublishing/Building-Real-world-Web-Applications-with-Vue.js-3/blob/main/09.tensorflow/.notes/9.10-ScoreCard.vue).'
  prefs: []
  type: TYPE_NORMAL
- en: In the component, we’re just displaying some of the metrics that were being
    collected on playthrough. They are all properties that are part of `gameStore`,
    so we have easy access to them.
  prefs: []
  type: TYPE_NORMAL
- en: 'In `End.vue`, we’ll import the `ScoreCard.vue` file and make some additions
    to the template:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: There’s not much going on here apart from the `<StartGame />` component, which
    we have reused to simply trigger a new game. That’s how you use slots! Now, we
    can work on the middle section!
  prefs: []
  type: TYPE_NORMAL
- en: Skipping to the end
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, let’s make sure we can complete a (very limited) flow by skipping all
    assignments. We’re going to implement the basic game flow in the `./views/Find.vue`
    file. Let’s take a look at the `script` tag since we have a lot going on in this
    file: [https://github.com/PacktPublishing/Building-Real-world-Web-Applications-with-Vue.js-3/blob/main/09.tensorflow/.notes/9.11-Find(script).vue](https://github.com/PacktPublishing/Building-Real-world-Web-Applications-with-Vue.js-3/blob/main/09.tensorflow/.notes/9.11-Find(script).vue).'
  prefs: []
  type: TYPE_NORMAL
- en: At the top of the `script` tag, we’re loading the properties and methods from
    the stores (*lines 3–15*). We use `appStore` to navigate to different pages and
    `gameStore` because that contains information about the progress of the current
    game.
  prefs: []
  type: TYPE_NORMAL
- en: We have some computed values that help in presenting and formatting data nicely.
    `currentRound` (*lines 17–19*) displays the progress of the game. We use `isPlaying`
    (*lines 21–23*) to determine the boundaries of the rounds versus the maximum set
    of rounds. Lastly, we have some fun randomized motivational quotes (*lines 25–29*)
    that we’ve loaded from our configuration file.
  prefs: []
  type: TYPE_NORMAL
- en: There are two methods in this component. One is to `skip` (*lines 31–39*) a
    round. The `skip` function tracks the number of rounds skipped (*line 32*) and
    modifies the player’s `score` (*lines 33–37*). We must make sure the score doesn’t
    fall below `0`. After skipping, we call the `newRound` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `newRound` function (*lines 41–47*) tracks what should happen: either the
    number of rounds has reached the maximum and we should navigate to the `End` state,
    or we should load a new category using the `getCategory` function from the store.
    To ensure we get started when we enter this `Find` state, we will call that `newRound`
    function in the `onMounted` hook.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let’s look at the template of the `Find.vue` file, where we connect the
    computed values and methods to a basic interface: [https://github.com/PacktPublishing/Building-Real-world-Web-Applications-with-Vue.js-3/blob/main/09.tensorflow/.notes/9.12-Find(template).vue](https://github.com/PacktPublishing/Building-Real-world-Web-Applications-with-Vue.js-3/blob/main/09.tensorflow/.notes/9.12-Find(template).vue).'
  prefs: []
  type: TYPE_NORMAL
- en: Again, there’s not much special going on here. We’re using the `<SkipRound />`
    component with the `@skipped` event to make sure we can move forward in rounds,
    regardless of whether we’ve been able to use object recognition.
  prefs: []
  type: TYPE_NORMAL
- en: 'Running the app at this stage should give us a result similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.3 – The basic game flow in place](img/B19563_09_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.3 – The basic game flow in place
  prefs: []
  type: TYPE_NORMAL
- en: You should be able to complete the entire flow now by skipping all of the rounds.
    A game like this makes more sense on a mobile device than a laptop or personal
    computer, so this would be a good time to make sure we can test the app properly.
  prefs: []
  type: TYPE_NORMAL
- en: Testing on a mobile device
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you’re building an app for a specific use case, it makes a lot of sense
    to test those cases as early as possible! While we can open the app in mobile
    views in our browser, it would make a lot of sense to run it on a mobile device
    as well. The first thing we can do is automatically expose the development server
    host by updating the `dev` script in the `package.json` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'This change automatically serves the content through your local network, so
    as long as your mobile device and development server are on the same network,
    you can access the app via the network address:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.4 – Exposing the development server to the network](img/B19563_09_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.4 – Exposing the development server to the network
  prefs: []
  type: TYPE_NORMAL
- en: 'We’re not there yet, though. The media feed is only accessible over a secure
    connection. Going with **Vite’s** recommendation in the official documentation
    ([https://vitejs.dev/config/server-options.html#server-https](https://vitejs.dev/config/server-options.html#server-https)),
    we’ll install a plugin for this using the terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the installation is completed, we’ll update the `vite.confis.ts` file
    so that it can use the plugin:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: After saving, we can restart the development server. The contents are now served
    over an HTTPS protocol. It is not using a signed certificate, so you will probably
    receive a warning from the browser upon first entry. You can now validate each
    step using your mobile device as well!
  prefs: []
  type: TYPE_NORMAL
- en: With that, we’ve built a basic flow from start to finish and we can test it
    on a mobile device. The game itself is not very interesting yet though, right?
    It’s time to add some object recognition to the game!
  prefs: []
  type: TYPE_NORMAL
- en: Object recognition from the camera
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This will be a change that involves a couple of steps. First, we’ll introduce
    a component that can capture video from the browser. We’ll create a `CameraDetect.vue`
    component in the `./components` folder: [https://github.com/PacktPublishing/Building-Real-world-Web-Applications-with-Vue.js-3/blob/main/09.tensorflow/.notes/9.13-CameraDetect.vue](https://github.com/PacktPublishing/Building-Real-world-Web-Applications-with-Vue.js-3/blob/main/09.tensorflow/.notes/9.13-CameraDetect.vue).'
  prefs: []
  type: TYPE_NORMAL
- en: The code in the `CameraDetect.vue` component uses composables from the `@vueuse`
    package to interact with the browsers’ `Devices` and `userMedia` APIs. We’re using
    `useDevicesList` to list the available cameras (*lines 33–40*) and populate a
    `<v-select />` component (*lines 4–14*). This allows the user to switch between
    available cameras.
  prefs: []
  type: TYPE_NORMAL
- en: The user needs to manually activate a camera (also when switching between cameras)
    for security reasons. The button in the component toggles the camera stream (*lines
    44–46*). To display the stream, we use `watchEffect` to pipe the stream into the
    `video` reference (*lines 48–50*). We can display the camera feed to the user
    by referencing the stream in the `<video />` HTML component (*line 20*).
  prefs: []
  type: TYPE_NORMAL
- en: Our stream is the replacement for the file upload of our prototype. We already
    have our store prepared to detect objects, so now, we’ll connect the stream to
    the `detect` function.
  prefs: []
  type: TYPE_NORMAL
- en: Detecting and recognizing objects on a stream
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the changes from our prototype is the way we provide images to the object
    recognition method. Using a stream means that we need to continuously process
    input, just as fast as the browser can.
  prefs: []
  type: TYPE_NORMAL
- en: Recognizing objects
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Our `detect` method from `objectStore` needs to be able to determine if the
    recognized objects are the objects we are looking for. We’ll add some capabilities
    to the function in the `object.ts` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Here, we’re adding an optional parameter called `className`. If it’s provided,
    we define a `filter` function. The filter is applied to the collection of recognized
    objects. If no `className` is provided, that filter function just defaults to
    returning `true`, which means it doesn’t filter out any objects. We only do this
    to provide backward compatibility for the `<ImageDetect />` component.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: When working on existing code bases, you have to keep these sorts of compatibility
    issues in mind while developing. In our case, backward compatibility was needed
    for a prototype function, so it’s not vital for our app. I’m highlighting this
    because, in large-scale applications with low test coverage, you may run into
    these solutions.
  prefs: []
  type: TYPE_NORMAL
- en: With our changes to the `object.ts` file, we can pass the stream to `objectStore`.
  prefs: []
  type: TYPE_NORMAL
- en: Detecting objects from the stream
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We’ll begin by passing the video stream’s contents to our updated `detect`
    function from `objectStore`. We’ll also include `gameStore` so that we can pass
    the current category as the `className` property. Let’s add these lines to the
    `CameraDetect.vue` file to get ourselves set up:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Don’t forget about the `watch` hook that we import from Vue; we’ll need it
    to monitor camera activity! Next, we’ll add a function called `detectObject` to
    our scripts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'What’s happening here? We’ve created a recursive function that continuously
    calls the `detect` method by passing the `video` and `currentCategory` values.
    To throttle the calls, we’re using `window.requestAnimationFrame` ([https://developer.mozilla.org/en-US/docs/Web/API/window/requestAnimationFrame](https://developer.mozilla.org/en-US/docs/Web/API/window/requestAnimationFrame)).
    Normally, this API is meant to query the browser when animating: the browser will
    accept the callback function once it’s ready to process it. This is perfect for
    our use case as well!'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can trigger the initial call as soon as the video is enabled. The `watch`
    hook we’ve imported can monitor the `enabled` variable and call the `detectObject`
    function once the video has been enabled:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, once we’ve found a match, we need to signal this to our application.
    We’ll add an `emit` event called `found` to trigger once the `detected` property
    has been populated with items:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: We’re returning the top match from the collection of `detected` items to the
    parent component.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: You can make testing easier by temporarily modifying the `objects` property
    in `objectsStore` so that it holds a couple of values of objects you have on hand,
    such as `person`. Later, you can restore the list to its previous state.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using Vue’s DevTools, you can test the app again. If you open the DevTools
    and navigate to the **Timeline** and **Component events** panels, once the camera
    has made a positive match, you will see continuous events being emitted (well,
    once for every animation frame):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.5 – Positive matches being emitted by the <CameraDetect /> component](img/B19563_09_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.5 – Positive matches being emitted by the <CameraDetect /> component
  prefs: []
  type: TYPE_NORMAL
- en: We can now connect the emitted event to the `Find` state. So, let’s move over
    to the `./views/Find.vue` file so that we can pick up on the `found` event and
    pull it into our little game!
  prefs: []
  type: TYPE_NORMAL
- en: Connecting detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If we open the `Find.vue` file, we can now add the event handler on the component
    to the template. We’ll also provide a `disable` property to control the camera
    by changing the component line to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'In the script block, we have to make some changes to both pick up on the `found`
    event and provide the value for the `detectionDisabled` property. Let’s look at
    the new component code: [https://github.com/PacktPublishing/Building-Real-world-Web-Applications-with-Vue.js-3/blob/main/09.tensorflow/.notes/9.14-Find.vue](https://github.com/PacktPublishing/Building-Real-world-Web-Applications-with-Vue.js-3/blob/main/09.tensorflow/.notes/9.14-Find.vue).'
  prefs: []
  type: TYPE_NORMAL
- en: We’ve added the `detectionDisabled` reactive variable (*line 51*) and are passing
    it down to the `<CameraDetect />` component. In the existing `skip` function,
    we’re setting the value of `detectionDisabled` to `false` (*line 68*). We’re also
    adding the `found` function (*lines 78–86*), where we update the `detectionDisabled`
    value as well and process a new score by calculating the certainty of the recognized
    object (*lines 81–83*) and updating `gameStore` (*line 84*). Similar to the `skip`
    function, we call the `newRound` function to progress the game.
  prefs: []
  type: TYPE_NORMAL
- en: Once the `newRound` function has been called, we update the `detectionDisabled`
    variable and set it to `true` to continue detection.
  prefs: []
  type: TYPE_NORMAL
- en: This would be another good time to test the app. In this case, upon detection,
    you will rapidly progress through the rounds toward the end. If recognition seems
    unreliable, you can lower `DETECTION_ACCURACY_THRESHOLD` in the `./``config.ts`
    file.
  prefs: []
  type: TYPE_NORMAL
- en: Wrapping up the game flow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although the game is now functional, it’s not playable since we’re not giving
    enough feedback to the user. With `appStore` at our disposal, one of the easiest
    solutions is to use the dialog! Once we’ve incorporated that, our mini-game will
    be complete!
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we’ll update the `CameraDetect.vue` file by adding the reference to
    the `dialogVisible` reactive value. To do this, add the following to the `script`
    tag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we’ll use `dialogVisible` in our `detectObject` function to assess whether
    it should call the `detect` function from `objectStore`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'This doesn’t affect our code yet since dialog has never been visible up until
    now. We’ll remedy that by making some changes to the `Find.vue` file as well.
    To define the contents of the dialog, we’ll add the following computed value to
    the `script` tag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'This returns a motivating line to display to the user. Feel free to modify
    this! The two functions that we’ll change are called `found` and `skipped`. Let’s
    have a look at the updated `found` function first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, we’re simply using the `appStore` method of `showDialog` to
    present a dialog to the user. The `<CameraDetect />` component is now able to
    detect when a dialog is visible and will stop detecting in the background. For
    the `skipped` function, we’ll add the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, these are very similar changes! Again, feel free to modify these
    contents to your liking as well.
  prefs: []
  type: TYPE_NORMAL
- en: Our game is now done! Hooray! We’ve now almost concluded our collection of applications.
    I think this game lends itself to being enriched with even more capabilities and
    more customization so that you can make it your own mini-game. From previous chapters,
    we’ve touched upon a lot of additional techniques and concepts you could apply
    or just get creative.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We started this chapter with a small prototype to experiment with a new sort
    of technology. Building something in an isolated environment helps you quickly
    understand how a certain technology can be adopted in an existing environment.
    As you’ve experienced, we were running into limitations that could not be resolved.
    In this case, it didn’t matter that much, since we have few business requirements
    to deal with.
  prefs: []
  type: TYPE_NORMAL
- en: We also learned how to leverage existing and available APIs from the browser
    itself to build something unconventional. When putting together a portfolio, standing
    out with unique projects can make you stand out as a developer. Building little
    projects while combining multiple technologies can help you understand how you
    can compose applications with them. This is a more intensive approach but results
    in a much better understanding of technologies.
  prefs: []
  type: TYPE_NORMAL
- en: Feel free to spend some time customizing projects from previous chapters. In
    the final chapter, we are going to create a portfolio to host online. This will
    be the perfect showcase for everything you’ve achieved so far!
  prefs: []
  type: TYPE_NORMAL
- en: 'Part 4: Wrapping Up'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The final part brings all the previous topics together. You will learn how to
    optimize Nuxt for a static site purpose and how to deploy to a web host. Then,
    we will look into automating workflows such as the deployment process. This section
    gives you the freedom to customize the output for your personal use and connects
    all previous chapters into a presentable portfolio.
  prefs: []
  type: TYPE_NORMAL
- en: 'This part has the following chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 10*](B19563_10.xhtml#_idTextAnchor321), *Building a Portfolio with
    Nuxt.js and Storyblok*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
