["```js\n// From AudioKit's Swift 3.x codebase\n\npublic enum ExportFormat {\n  case wav\n  case aif\n  case mp4\n  case m4a\n  case caf\n\n  fileprivate var UTI: CFString {\n    switch self {\n    case .wav:\n      return AVFileTypeWAVE as CFString\n    case .aif:\n      return AVFileTypeAIFF as CFString\n    case .mp4:\n      return AVFileTypeAppleM4A as CFString\n    case .m4a:\n      return AVFileTypeAppleM4A as CFString\n    case .caf:\n      return AVFileTypeCoreAudioFormat as CFString\n    }\n  }\n\n  static var supportedFileExtensions: [String] {\n    return [\"wav\", \"aif\", \"mp4\", \"m4a\", \"caf\"]\n  }\n}\n```", "```js\npublic enum ExportFormat: Int {\n  case wav\n  case aif\n  case mp4\n  case m4a\n  case caf\n}\n\nstatic public func stringUTI(type: ExportFormat) -> CFString {\n  switch type {\n  case .wav:\n    return AVFileTypeWAVE as CFString\n  case .aif:\n    return AVFileTypeAIFF as CFString\n  case .mp4:\n    return AVFileTypeAppleM4A as CFString\n  case .m4a:\n    return AVFileTypeAppleM4A as CFString\n  case .caf:\n    return AVFileTypeCoreAudioFormat as CFString\n  }\n}\n\nstatic public var supportedFileExtensions: [String] {\n  return [\"wav\", \"aif\", \"mp4\", \"m4a\", \"caf\"]\n}\n```", "```js\n{\n  \"name\": \"nativescript-audiokit\",\n  \"version\": \"1.0.0\",\n  \"nativescript\": {\n    \"platforms\": {\n      \"ios\": \"3.0.0\"\n    }\n  }\n}\n```", "```js\ntns plugin add nativescript-audiokit\n```", "```js\nEMBEDDED_CONTENT_CONTAINS_SWIFT = true\n```", "```js\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n<plist version=\"1.0\">\n<dict>\n  <key>NSMicrophoneUsageDescription</key>\n <string>Requires access to microphone.</string>\n <key>UIBackgroundModes</key>\n <array>\n <string>audio</string>\n </array>\n <key>UIFileSharingEnabled</key> \n <true/>\n</dict>\n</plist>\n```", "```js\ntns plugin remove nativescript-audiokit\ntns plugin add nativescript-audiokit\n```", "```js\nnpm i tns-platform-declarations --save-dev\n```", "```js\n/// <reference path=\"./node_modules/tns-platform-declarations/ios.d.ts\" />\n/// <reference path=\"./node_modules/tns-platform-declarations/android.d.ts\" />\n```", "```js\nTNS_TYPESCRIPT_DECLARATIONS_PATH=\"$(pwd)/typings\" tns build ios\n```", "```js\n/// <reference path=\"./node_modules/tns-platform-declarations/ios.d.ts\" />\n/// <reference path=\"./node_modules/tns-platform-declarations/android.d.ts\" />\n/// <reference path=\"./typings/objc!AudioKit.d.ts\" />\n```", "```js\nimport { Observable } from 'data/observable';\nimport { knownFolders } from 'file-system';\n\n// all available states for the recorder \nexport enum RecordState {\n  readyToRecord,\n  recording,\n  readyToPlay,\n  playing,\n  saved,\n  finish\n}\n\n// available events\nexport interface IRecordEvents {\n  stateChange: string;\n}\n\n// for use when saving files\nconst documentsFilePath = function(filename: string) {\n  return `${knownFolders.documents().path}/${filename}`;\n}\n\nexport class RecordModel extends Observable {\n\n  // available events to listen to\n  private _events: IRecordEvents;\n\n  // control nodes \n  private _mic: AKMicrophone;\n  private _micBooster: AKBooster;\n  private _recorder: AKNodeRecorder;\n\n  // mixers\n  private _micMixer: AKMixer;\n  private _mainMixer: AKMixer;\n\n  // state\n  private _state: number = RecordState.readyToRecord;\n\n  // the final saved path to use \n  private _savedFilePath: string;\n\n  constructor() {\n    super();\n    // setup the event names\n    this._setupEvents();\n\n    // setup recording environment\n    // clean any tmp files from previous recording sessions\n    (<any>AVAudioFile).cleanTempDirectory();\n\n    // audio setup \n    AKSettings.setBufferLength(BufferLength.Medium);\n\n    try {\n      // ensure audio session is PlayAndRecord\n      // allows mixing with other tracks while recording\n      AKSettings.setSessionWithCategoryOptionsError(\n        SessionCategory.PlayAndRecord, \n        AVAudioSessionCategoryOptions.DefaultToSpeaker\n      );\n    } catch (err) {\n      console.log('AKSettings error:', err);\n    }\n\n    // setup mic with it's own mixer\n    this._mic = AKMicrophone.alloc().init();\n    this._micMixer = AKMixer.alloc().init(null);\n    this._micMixer.connect(this._mic);\n    // Helps provide mic monitoring when headphones are plugged in\n    this._micBooster = AKBooster.alloc().initGain(<any>this._micMixer, 0);\n\n    try {\n      // recorder takes the micMixer input node\n      this._recorder = AKNodeRecorder.alloc()\n        .initWithNodeFileError(<any>this._micMixer, null);\n    } catch (err) {\n      console.log('AKNodeRecorder init error:', err);\n    }\n\n    // overall main mixer uses micBooster\n    this._mainMixer = AKMixer.alloc().init(null);\n    this._mainMixer.connect(this._micBooster);\n\n    // single output set to mainMixer \n    AudioKit.setOutput(<any>this._mainMixer);\n    // start the engine!\n    AudioKit.start();\n  }\n\n  public get events(): IRecordEvents {\n    return this._events;\n  }\n\n  public get mic(): AKMicrophone {\n    return this._mic;\n  }\n\n  public get recorder(): AKNodeRecorder {\n    return this._recorder;\n  }\n\n  public get audioFilePath(): string {\n    if (this._recorder) {\n      return this._recorder.audioFile.url.absoluteString;\n    }\n    return '';\n  }\n\n  public get state(): number {\n    return this._state;\n  }\n\n  public set state(value: number) {\n    this._state = value;\n    // always emit state changes\n    this._emitEvent(this._events.stateChange, this._state);\n  }\n\n  public get savedFilePath() {\n    return this._savedFilePath;\n  }\n\n  public set savedFilePath(value: string) {\n    this._savedFilePath = value;\n    if (this._savedFilePath)\n      this.state = RecordState.saved;\n  }\n\n  public toggleRecord() {\n    if (this._state !== RecordState.recording) {\n      // just force ready to record\n      // when coming from any state other than recording\n      this.state = RecordState.readyToRecord;\n\n      if (this._recorder) {\n        try {\n          // resetting (clear previous recordings)\n          this._recorder.resetAndReturnError();\n        } catch (err) {\n          console.log('Recorder reset error:', err);\n        }\n      }\n    }\n\n    switch (this._state) {\n      case RecordState.readyToRecord:\n        if (AKSettings.headPhonesPlugged) {\n          // Microphone monitoring when headphones plugged\n          this._micBooster.gain = 1;\n        }\n\n        try {\n          this._recorder.recordAndReturnError();\n          this.state = RecordState.recording;\n        } catch (err) {\n          console.log('Recording failed:', err);\n        }\n        break;\n      case RecordState.recording:\n        this.state = RecordState.readyToPlay;\n        this._recorder.stop();\n        // Microphone monitoring muted when playing back\n        this._micBooster.gain = 0;\n        break;\n    }\n  } \n\n  public togglePlay() {\n    if (this._state === RecordState.readyToPlay) {\n      this.state = RecordState.playing;\n    } else {\n      this.stopPlayback();\n    }\n  }\n\n  public stopPlayback() {\n    if (this.state !== RecordState.recording) {\n      this.state = RecordState.readyToPlay;\n    }\n  }\n\n  public save() {\n    let fileName = `recording-${Date.now()}.m4a`;\n    this._recorder.audioFile\n    .exportAsynchronouslyWithNameBaseDirExportFormatFromSampleToSampleCallback(\n      fileName, BaseDirectory.Documents, ExportFormat.M4a, null, null, \n      (af: AKAudioFile, err: NSError) => {\n        this.savedFilePath = documentsFilePath(fileName);\n      });\n  }\n\n  public finish() {\n    this.state = RecordState.finish;\n  }\n\n  private _emitEvent(eventName: string, data?: any) {\n    let event = {\n      eventName,\n      data,\n      object: this\n    };\n    this.notify(event);\n  }\n\n  private _setupEvents() {\n    this._events = {\n      stateChange: 'stateChange'\n    };\n  }\n}\n```", "```js\n(<any>AVAudioFile).cleanTempDirectory();\n```", "```js\nAKSettings.setSessionWithCategoryOptionsError(\n  SessionCategory.PlayAndRecord, \n  AVAudioSessionCategoryOptions.DefaultToSpeaker\n);\n```", "```js\nthis._mic = AKMicrophone.alloc().init();\nthis._micMixer = AKMixer.alloc().init(null);\nthis._micMixer.connect(this._mic);\n```", "```js\nthis._recorder.audioFile\n  .exportAsynchronouslyWithNameBaseDirExportFormatFromSampleToSampleCallback(\n    fileName, BaseDirectory.Documents, ExportFormat.M4a, null, null, \n    (af: AKAudioFile, err: NSError) => {\n      this.savedFilePath = documentsFilePath(fileName);\n  });\n```", "```js\nexportAsynchronously(name:baseDir:exportFormat:fromSample:toSample:callback:)\n// converted to NativeScript:\nexportAsynchronouslyWithNameBaseDirExportFormatFromSampleToSampleCallback\n```", "```js\nimport { View, Property } from 'ui/core/view';\nimport { Color } from 'color';\n\n// Support live microphone display as well as static audio file renders\ntype WaveformType = 'mic' | 'file';\n\n// define properties\nexport const plotColorProperty = new Property<Waveform, string>({ name: 'plotColor' });\nexport const plotTypeProperty = new Property<Waveform, string>({ name: 'plotType' });\nexport const fillProperty = new Property<Waveform, string>({ name: 'fill' });\nexport const mirrorProperty = new Property<Waveform, string>({ name: 'mirror' });\n\nexport interface IWaveformModel {\n  readonly target: any;\n  dispose(): void;\n}\nexport class Waveform extends View {\n  private _model: IWaveformModel;\n  private _type: WaveformType;\n\n  public set type(value: WaveformType) {\n    this._type = value;\n  }\n\n  public get type() {\n    return this._type;\n  }\n\n  public set model(value: IWaveformModel) {\n    this._model = value;\n  }\n\n  public get model() {\n    return this._model;\n  }\n\n  createNativeView() {\n    switch (this.type) {\n      case 'mic':\n        this.nativeView = AKNodeOutputPlot.alloc()\n          .initFrameBufferSize(this._model.target, CGRectMake(0, 0, 0, 0), 1024);\n        break;\n      case 'file':\n        this.nativeView = EZAudioPlot.alloc().init();\n        break;\n    }\n    return this.nativeView;\n  }\n\n  initNativeView() {\n    if (this._type === 'file') {\n      // init file with the model's target\n      // target should be absolute url to path of file\n      let file = EZAudioFile.alloc()\n        .initWithURL(NSURL.fileURLWithPath(this._model.target));\n      // render the file's data as a waveform\n      let data = file.getWaveformData();\n      (<EZAudioPlot>this.nativeView)\n        .updateBufferWithBufferSize(data.buffers[0], data.bufferSize);\n    }\n  }\n\n  disposeNativeView() {\n    if (this.model && this.model.dispose) this.model.dispose();\n  }\n\n  [plotColorProperty.setNative](value: string) {\n    this.nativeView.color = new Color(value).ios;\n  }\n\n  [fillProperty.setNative](value: string) {\n    this.nativeView.shouldFill = value === 'true';\n  }\n\n  [mirrorProperty.setNative](value: string) {\n    this.nativeView.shouldMirror = value === 'true';\n  }\n\n  [plotTypeProperty.setNative](value: string) {\n    switch (value) {\n      case 'buffer':\n        this.nativeView.plotType = EZPlotType.Buffer;\n        break;\n      case 'rolling':\n        this.nativeView.plotType = EZPlotType.Rolling;\n        break;\n    }\n  }\n}\n\n// register properties with it's type\nplotColorProperty.register(Waveform);\nplotTypeProperty.register(Waveform);\nfillProperty.register(Waveform);\nmirrorProperty.register(Waveform);\n```", "```js\n// define properties\nexport const plotColorProperty = new Property<Waveform, string>({ name: 'plotColor' });\nexport const plotTypeProperty = new Property<Waveform, string>({ name: 'plotType' });\nexport const fillProperty = new Property<Waveform, string>({ name: 'fill' });\nexport const mirrorProperty = new Property<Waveform, string>({ name: 'mirror' });\n```", "```js\n[plotColorProperty.setNative](value: string) {\n  this.nativeView.color = new Color(value).ios;\n}\n```", "```js\n// register properties\nplotColorProperty.register(Waveform);\nplotTypeProperty.register(Waveform);\nfillProperty.register(Waveform);\nmirrorProperty.register(Waveform);\n```", "```js\nexport interface IWaveformModel {\n  readonly target: any;\n  dispose(): void;\n}\n```", "```js\ncreateNativeView() {\n  switch (this.type) {\n    case 'mic':\n      this.nativeView = AKNodeOutputPlot.alloc()\n        .initFrameBufferSize(this._model.target, CGRectMake(0, 0, 0, 0), 1024);\n      break;\n    case 'file':\n      this.nativeView = EZAudioPlot.alloc().init();\n      break;\n  }\n  return this.nativeView;\n}\n```", "```js\n...\n// register nativescript custom components\nimport { registerElement } from 'nativescript-angular/element-registry';\nimport { Waveform } from './native/waveform';\nregisterElement('Waveform', () => Waveform);\n...\n@NgModule({...\nexport class SharedModule {...\n```", "```js\nimport { IWaveformModel } from '../../shared/native/waveform';\nimport { knownFolders } from 'file-system';\n\nexport enum RecordState {\n  readyToRecord,\n  recording,\n  readyToPlay,\n  playing,\n  saved,\n  finish\n}\n\nexport interface IRecordEvents {\n  stateChange: string;\n}\n\nexport interface IRecordModel extends IWaveformModel {\n  readonly events: IRecordEvents;\n  readonly recorder: any;\n  readonly audioFilePath: string;\n  state: number; \n  savedFilePath: string;\n  toggleRecord(): void;\n  togglePlay(startTime?: number, when?: number): void;\n  stopPlayback(): void;\n  save(): void;\n  finish(): void;\n}\n\nexport const documentsFilePath = function(filename: string) {\n  return `${knownFolders.documents().path}/${filename}`;\n}\n```", "```js\nexport * from './record-common.model';\nexport * from './record.model';\n```", "```js\nimport { Observable } from 'data/observable';\nimport { IRecordModel, IRecordEvents, RecordState, documentsFilePath } from './common';\n\nexport class RecordModel extends Observable implements IRecordModel {\n  ...\n  public get target() {\n return this._mic;\n }\n\n  public dispose() {\n AudioKit.stop();\n // cleanup\n this._mainMixer = null;\n this._recorder = null;\n this._micBooster = null;\n this._micMixer = null;\n this._mic = null;\n // clean out tmp files\n (<any>AVAudioFile).cleanTempDirectory();\n }\n  ...\n```", "```js\n<ActionBar title=\"Record\" icon=\"\" class=\"action-bar\">\n  <NavigationButton visibility=\"collapsed\"></NavigationButton>\n  <ActionItem text=\"Cancel\" \n    ios.systemIcon=\"1\" android.systemIcon=\"ic_menu_back\" \n    (tap)=\"cancel()\"></ActionItem>\n</ActionBar>\n<FlexboxLayout class=\"record\">\n  <GridLayout rows=\"auto\" columns=\"auto,*,auto\" class=\"p-10\" *ngIf=\"isModal\">\n    <Button text=\"Cancel\" (tap)=\"cancel()\" \n      row=\"0\" col=\"0\" class=\"c-white\"></Button>\n  </GridLayout>\n  <Waveform class=\"waveform\" \n    [model]=\"recorderService.model\" \n    type=\"mic\" \n    plotColor=\"yellow\" \n    fill=\"false\" \n    mirror=\"true\" \n    plotType=\"buffer\">\n  </Waveform>\n  <StackLayout class=\"p-5\">\n    <FlexboxLayout class=\"controls\">\n      <Button text=\"Rewind\" class=\"btn text-center\" \n        (tap)=\"recorderService.rewind()\" \n        [isEnabled]=\"state == recordState.readyToPlay || state == recordState.playing\">\n      </Button>\n      <Button [text]=\"recordBtn\" class=\"btn text-center\" \n        (tap)=\"recorderService.toggleRecord()\" \n        [isEnabled]=\"state != recordState.playing\"></Button>\n      <Button [text]=\"playBtn\" class=\"btn text-center\" \n        (tap)=\"recorderService.togglePlay()\" \n        [isEnabled]=\"state == recordState.readyToPlay || state == recordState.playing\">\n      </Button>\n    </FlexboxLayout>\n    <FlexboxLayout class=\"controls bottom\" \n      [class.recording]=\"state == recordState.recording\">\n      <Button text=\"Save\" class=\"btn\" \n        [class.save-ready]=\"state == recordState.readyToPlay\" \n        [isEnabled]=\"state == recordState.readyToPlay\"\n        (tap)=\"recorderService.save()\"></Button>\n    </FlexboxLayout>\n  </StackLayout>\n</FlexboxLayout>\n```", "```js\n.record {\n  background-color: rgba(0,0,0,.5);\n  flex-direction: column;\n  justify-content: space-around;\n  align-items: stretch;\n  align-content: center;\n}\n\n.record .waveform {\n  background-color: transparent;\n  order: 1;\n  flex-grow: 1;\n}\n\n.controls {\n  width: 100%;\n  height: 200;\n  flex-direction: row;\n  flex-wrap: nowrap;\n  justify-content: center;\n  align-items: center;\n  align-content: center;\n}\n\n.controls.bottom {\n  height: 90;\n  justify-content: flex-end;\n}\n\n.controls.bottom.recording {\n  background-color: #B0342D;\n}\n\n.controls.bottom .btn {\n  border-radius: 40;\n  height: 62;\n  padding: 2;\n}\n\n.controls.bottom .btn.save-ready {\n  background-color: #42B03D;\n}\n\n.controls .btn {\n  color: #fff;\n}\n\n.controls .btn[isEnabled=false] {\n  background-color: transparent;\n  color: #777;\n}\n```", "```js\n// angular\nimport { Component, OnInit, OnDestroy, Optional } from '@angular/core';\n\n// libs\nimport { Subscription } from 'rxjs/Subscription';\n\n// nativescript\nimport { RouterExtensions } from 'nativescript-angular/router';\nimport { ModalDialogParams } from 'nativescript-angular/directives/dialogs';\nimport { isIOS } from 'platform';\n\n// app\nimport { RecordModel, RecordState } from '../models';\nimport { RecorderService } from '../services/recorder.service';\n\n@Component({\n  moduleId: module.id,\n  selector: 'record',\n  templateUrl: 'record.component.html',\n  styleUrls: ['record.component.css']\n})\nexport class RecordComponent implements OnInit, OnDestroy { \n  public isModal: boolean;\n  public recordBtn: string = 'Record';\n  public playBtn: string = 'Play';\n  public state: number;\n  public recordState: any = {};\n\n  private _sub: Subscription;\n\n  constructor(\n    private router: RouterExtensions,\n    @Optional() private params: ModalDialogParams,\n    public recorderService: RecorderService\n  ) { \n    // prepare service for brand new recording\n    recorderService.setupNewRecording();\n\n    // use RecordState enum names as reference in view\n    for (let val in RecordState ) {\n      if (isNaN(parseInt(val))) {\n        this.recordState[val] = RecordState[val];\n      }\n    }\n  }\n\n  ngOnInit() {\n    if (this.params && this.params.context.isModal) {\n      this.isModal = true;\n    }\n    this._sub = this.recorderService.state$.subscribe((state: number) => {\n      this.state = state;\n      switch (state) {\n        case RecordState.readyToRecord:\n        case RecordState.readyToPlay:\n          this._resetState();\n          break;\n        case RecordState.playing:\n          this.playBtn = 'Pause';\n          break;\n        case RecordState.recording:\n          this.recordBtn = 'Stop';\n          break;\n        case RecordState.finish:\n          this._cleanup();\n          break;\n      }\n    });\n  }\n\n  ngOnDestroy() {\n    if (this._sub) this._sub.unsubscribe();\n  }\n\n  public cancel() {\n    this._cleanup();\n  }\n\n  private _cleanup() {\n    this.recorderService.cleanup();\n    invokeOnRunLoop(() => {\n      if (this.isModal) {\n        this._close();\n      } else {\n        this._back();\n      }\n    });\n  }\n\n  private _close() {\n    this.params.closeCallback();\n  }\n\n  private _back() {\n    this.router.back();\n  }\n\n  private _resetState() {\n    this.recordBtn = 'Record';\n    this.playBtn = 'Play';\n  }\n}\n\n/**\n * Needed on iOS to prevent this potential exception:\n * \"This application is modifying the autolayout engine from a background thread after the engine was accessed from the main thread. This can lead to engine corruption and weird crashes.\"\n */\nconst invokeOnRunLoop = (function () {\n  if (isIOS) {\n    var runloop = CFRunLoopGetMain();\n    return function(func) {\n      CFRunLoopPerformBlock(runloop, kCFRunLoopDefaultMode, func);\n      CFRunLoopWakeUp(runloop);\n    }\n  } else {\n    return function (func) {\n      func();\n    }\n  }\n}());\n```", "```js\n// angular\nimport { Component, Input, Output, EventEmitter } from '@angular/core';\n\n// nativescript\nimport { RouterExtensions } from 'nativescript-angular/router'; \n\nimport { PlayerService } from '../../../player/services/player.service';\n\n@Component({\n  moduleId: module.id,\n  selector: 'action-bar',\n  templateUrl: 'action-bar.component.html'\n})\nexport class ActionBarComponent {\n  ...\n  @Output() showRecordModal: EventEmitter<any> = new EventEmitter();\n  ...\n  constructor(\n    private router: RouterExtensions,\n private playerService: PlayerService\n  ) { }\n\n  public record() {\n if (this.playerService.composition && \n this.playerService.composition.tracks.length) {\n      // display recording UI as modal\n this.showRecordModal.next();\n } else {\n      // navigate to it\n this.router.navigate(['/record']);\n }\n }\n}\n```", "```js\n<ActionItem (tap)=\"record()\" ios.position=\"right\">\n  <Button text=\"Record\" class=\"action-item\"></Button>\n</ActionItem>\n```", "```js\n<action-bar [title]=\"composition.name\" (showRecordModal)=\"showRecordModal()\"></action-bar>\n<GridLayout rows=\"*, auto\" columns=\"*\" class=\"page\">\n  <track-list [tracks]=\"composition.tracks\" row=\"0\" col=\"0\"></track-list>\n  <player-controls [composition]=\"composition\" row=\"1\" col=\"0\"></player-controls>\n</GridLayout>\n```", "```js\n// angular\nimport { Injectable, NgModuleFactory, NgModuleFactoryLoader, ViewContainerRef, NgModuleRef } from '@angular/core';\n\n// nativescript\nimport * as dialogs from 'ui/dialogs';\nimport { ModalDialogService } from 'nativescript-angular/directives/dialogs';\n\n@Injectable()\nexport class DialogService {\n\n  constructor(\n private moduleLoader: NgModuleFactoryLoader,\n private modalService: ModalDialogService\n ) { }\n\n  public openModal(componentType: any, vcRef: ViewContainerRef, context?: any, modulePath?: string): Promise<any> {\n return new Promise((resolve, reject) => {\n\n const launchModal = (moduleRef?: NgModuleRef<any>) => {\n this.modalService.showModal(componentType, {\n moduleRef,\n viewContainerRef: vcRef,\n context\n }).then(resolve, reject);\n };\n\n      if (modulePath) {\n        // lazy load module which contains component to open in modal\n        this.moduleLoader.load(modulePath)\n .then((module: NgModuleFactory<any>) => {\n launchModal(module.create(vcRef.parentInjector));\n });\n } else {\n        // open component in modal known to be available without lazy loading\n        launchModal();\n }\n });\n }\n  ...\n}\n```", "```js\n// angular\nimport { Component, OnInit, OnDestroy, ViewContainerRef } from '@angular/core';\nimport { ActivatedRoute } from '@angular/router';\nimport { Subscription } from 'rxjs/Subscription';\n\n// app\nimport { DialogService } from '../../core/services/dialog.service';\nimport { MixerService } from '../services/mixer.service';\nimport { CompositionModel } from '../../shared/models';\nimport { RecordComponent } from '../../recorder/components/record.component';\n\n@Component({\n moduleId: module.id,\n selector: 'mixer',\n templateUrl: 'mixer.component.html'\n})\nexport class MixerComponent implements OnInit, OnDestroy {\n\n  public composition: CompositionModel;\n  private _sub: Subscription;\n\n  constructor(\n    private route: ActivatedRoute,\n    private mixerService: MixerService,\n    private dialogService: DialogService,\n private vcRef: ViewContainerRef\n  ) { }\n\n  public showRecordModal() {\n this.dialogService.openModal(\n      RecordComponent,\n      this.vcRef,\n      { isModal: true },\n      './modules/recorder/recorder.module#RecorderModule'\n    );\n }\n  ...\n}\n```", "```js\n// angular\nimport { Injectable } from '@angular/core';\nimport { Subject } from 'rxjs/Subject';\nimport { Subscription } from 'rxjs/Subscription';\n\n// app\nimport { DialogService } from '../../core/services/dialog.service';\nimport { RecordModel, RecordState } from '../models';\nimport { PlayerService } from '../../player/services/player.service';\nimport { TrackModel } from '../../shared/models/track.model';\n\n@Injectable()\nexport class RecorderService {\n  public state$: Subject<number> = new Subject();\n  public model: RecordModel;\n  private _trackId: number;\n  private _sub: Subscription;\n\n  constructor(\n    private playerService: PlayerService,\n    private dialogService: DialogService\n  ) { } \n\n  public setupNewRecording() {\n    this.model = new RecordModel();\n    this._trackId = undefined; // reset\n\n    this.model.on(this.model.events.stateChange, this._stateHandler.bind(this));\n    this._sub = this.playerService.complete$.subscribe(_ => {\n      this.model.stopPlayback();\n    });\n  }\n\n  public toggleRecord() {\n    this.model.toggleRecord();\n  }\n\n  public togglePlay() {\n    this.model.togglePlay();\n  }\n\n  public rewind() {\n    this.playerService.seekTo(0); // reset to 0\n  }\n\n  public save() {\n    this.model.save();\n  }\n\n  public cleanup() {\n    // unbind event listener\n    this.model.off(this.model.events.stateChange, this._stateHandler.bind(this));\n    this._sub.unsubscribe();\n\n    if (!this.model.savedFilePath) {\n      // user did not save recording, cleanup\n      this.playerService.removeTrack(this._trackId);\n    }\n  }\n\n  private _stateHandler(e) {\n    this.state$.next(e.data);\n\n    switch (e.data) {\n      case RecordState.readyToRecord:\n        this._stopMix();\n        break; \n      case RecordState.readyToPlay:\n        this._stopMix();\n        this._trackId = this.playerService\n          .updateCompositionTrack(this._trackId, this.model.audioFilePath);\n        break;\n      case RecordState.playing:\n        this._playMix();\n        break;\n      case RecordState.recording:\n        this._playMix(this._trackId);\n        break;\n      case RecordState.saved:\n        this._handleSaved();\n        break;\n    }\n  }\n\n  private _playMix(excludeTrackId?: number) {\n    if (!this.playerService.playing) {\n      // ensure mix plays\n      this.playerService.togglePlay(excludeTrackId);\n    }\n  }\n\n  private _stopMix() {\n    if (this.playerService.playing) {\n      // ensure mix stops\n      this.playerService.togglePlay();\n    }\n    // always reset to beginning\n    this.playerService.seekTo(0);\n  }\n\n  private _handleSaved() {\n    this._sub.unsubscribe();\n    this._stopMix();\n    this.playerService\n      .updateCompositionTrack(this._trackId, this.model.savedFilePath);\n    this.playerService.saveComposition();\n    this.model.finish();\n  } \n}\n```", "```js\ncase RecordState.readyToPlay:\n  this._stopMix();\n  this._trackId = this.playerService\n    .updateCompositionTrack(this._trackId, this.model.audioFilePath);\n  break;\n```", "```js\ncase RecordState.recording:\n  this._playMix(this._trackId);\n  break;\n```", "```js\npublic cleanup() {\n  // unbind event listener\n  this.model.off(this.model.events.stateChange, this._stateHandler.bind(this));\n  this._sub.unsubscribe();\n\n  if (!this.model.savedFilePath) {\n    // user did not save recording, cleanup\n    this.playerService.removeTrack(this._trackId);\n  }\n}\n```", "```js\n...\nimport { MixerService } from '../../mixer/services/mixer.service';\n\n@Injectable()\nexport class PlayerService {\n\n  // default name of new tracks\n  private _defaultTrackName: string = 'New Track';\n  ...\n  constructor(\n    private ngZone: NgZone,\n    private mixerService: MixerService\n  ) { ... }\n  ...\n  public saveComposition() {\n this.mixerService.save(this.composition);\n }\n\n  public togglePlay(excludeTrackId?: number) {\n    if (this._trackPlayers.length) {\n      this.playing = !this.playing;\n      if (this.playing) {\n        this.play(excludeTrackId);\n      } else {\n        this.pause();\n      }\n    }\n  }\n\n  public play(excludeTrackId?: number) {\n    // for iOS playback sync\n    let shortStartDelay = .01;\n    let now = 0;\n\n    for (let i = 0; i < this._trackPlayers.length; i++) {\n      let track = this._trackPlayers[i];\n      if (excludeTrackId !== track.trackId) {\n        if (isIOS) {\n          if (i == 0) now = track.player.ios.deviceCurrentTime;\n          (<any>track.player).playAtTime(now + shortStartDelay);\n        } else {\n          track.player.play();\n        }\n      }\n    }\n  }\n\n  public addTrack(track: ITrack): Promise<any> {\n return new Promise((resolve, reject) => {\n\n let trackPlayer = this._trackPlayers.find((p) => p.trackId === track.id);\n if (!trackPlayer) {\n        // new track\n trackPlayer = new TrackPlayerModel();\n this._composition.tracks.push(track);\n this._trackPlayers.push(trackPlayer);\n } else {\n        // update track\n this.updateTrack(track);\n }\n\n trackPlayer.load(\n track,\n this._trackComplete.bind(this),\n this._trackError.bind(this)\n ).then(_ => {\n        // report longest duration as totalDuration\n this._updateTotalDuration();\n resolve();\n });\n })\n }  public updateCompositionTrack(trackId: number, filepath: string): number {\n let track;\n if (!trackId) {\n      // Create a new track\n let cnt = this._defaultTrackNamesCnt();\n track = new TrackModel({\n name: `${this._defaultTrackName}${cnt ? ' ' + (cnt + 1) : ''}`,\n order: this.composition.tracks.length,\n filepath\n });\n trackId = track.id;\n } else {\n      // find by id and update\n track = this.findTrack(trackId);\n track.filepath = filepath;\n }\n this.addTrack(track);\n return trackId;\n }\n\n  private _defaultTrackNamesCnt() {\n return this.composition.tracks\n .filter(t => t.name.startsWith(this._defaultTrackName)).length;\n }\n  ...\n```", "```js\n...\n// import { PROVIDERS } from './services'; // commented out now\n\n@NgModule({\n ...\n // providers: [...PROVIDERS], // no longer provided here\n ...\n})\nexport class PlayerModule {}\n```", "```js\n...\n// import { PROVIDERS } from './services'; // commented out now\n\n@NgModule({\n ...\n // providers: [...PROVIDERS], // no longer provided here\n ...\n})\nexport class MixerModule {}\n```", "```js\n...\nimport { PROVIDERS } from './services';\nimport { PROVIDERS as MIXER_PROVIDERS } from '../mixer/services';\nimport { PROVIDERS as PLAYER_PROVIDERS } from '../player/services';\n\n...\n\n@NgModule({\n  ...\n  providers: [\n    ...PROVIDERS,\n    ...MIXER_PROVIDERS,\n ...PLAYER_PROVIDERS\n  ],\n  ...\n})\nexport class CoreModule {\n```", "```js\ntsc app/modules/recorder/models/record.model.ts references.d.ts -d true\n```", "```js\n...\nreadonly target: AKMicrophone;\nreadonly recorder: AKNodeRecorder;\n...\n```", "```js\nimport { Observable } from 'data/observable';\nimport { IRecordModel, IRecordEvents } from './common';\nexport declare class RecordModel extends Observable implements IRecordModel {\n  readonly events: IRecordEvents;\n  readonly target: any;\n  readonly recorder: any;\n  readonly audioFilePath: string;\n  state: number;\n  savedFilePath: string;\n  toggleRecord(): void;\n  togglePlay(): void;\n  stopPlayback(): void;\n  save(): void;\n  dispose(): void;\n  finish(): void;\n}\n```", "```js\nimport { Observable } from 'data/observable';\nimport { IRecordModel, IRecordEvents, RecordState, documentsFilePath } from './common';\n\nexport class RecordModel extends Observable implements IRecordModel {\n\n  // available events to listen to\n  private _events: IRecordEvents;\n\n  // recorder \n  private _recorder: any;\n\n  // state\n  private _state: number = RecordState.readyToRecord;\n\n  // the final saved path to use \n  private _savedFilePath: string;\n\n  constructor() {\n    super();\n    this._setupEvents();\n    // TODO\n  }\n\n  public get events(): IRecordEvents {\n    return this._events;\n  }\n\n  public get target() {\n    // TODO\n  }\n\n  public get recorder(): any {\n    return this._recorder;\n  }\n\n  public get audioFilePath(): string {\n    return ''; // TODO\n  }\n\n  public get state(): number {\n    return this._state;\n  }\n\n  public set state(value: number) {\n    this._state = value;\n    this._emitEvent(this._events.stateChange, this._state);\n  }\n\n  public get savedFilePath() {\n    return this._savedFilePath;\n  }\n\n  public set savedFilePath(value: string) {\n    this._savedFilePath = value;\n    if (this._savedFilePath)\n      this.state = RecordState.saved;\n  }\n\n  public toggleRecord() {\n    if (this._state !== RecordState.recording) {\n      // just force ready to record\n      // when coming from any state other than recording\n      this.state = RecordState.readyToRecord;\n    }\n\n    switch (this._state) {\n      case RecordState.readyToRecord:\n        this.state = RecordState.recording;\n        break;\n      case RecordState.recording:\n        this._recorder.stop();\n        this.state = RecordState.readyToPlay;\n        break;\n    }\n  }\n\n  public togglePlay() {\n    if (this._state === RecordState.readyToPlay) {\n      this.state = RecordState.playing;\n    } else {\n      this.stopPlayback();\n    }\n  }\n\n  public stopPlayback() {\n    if (this.state !== RecordState.recording) {\n      this.state = RecordState.readyToPlay;\n    }\n  }\n\n  public save() {\n    // we will want to do this\n    // this.savedFilePath = documentsFilePath(fileName);\n  }\n\n  public dispose() {\n    // TODO\n  }\n\n  public finish() {\n    this.state = RecordState.finish;\n  }\n\n  private _emitEvent(eventName: string, data?: any) {\n    let event = {\n      eventName,\n      data,\n      object: this\n    };\n    this.notify(event);\n  }\n\n  private _setupEvents() {\n    this._events = {\n      stateChange: 'stateChange'\n    };\n  }\n}\n```", "```js\nimport { Observable } from 'data/observable';\nimport { IRecordModel, IRecordEvents, RecordState, documentsFilePath } from './common';\nimport { TNSRecorder, AudioRecorderOptions } from 'nativescript-audio';\nimport { Subject } from 'rxjs/Subject';\nimport * as permissions from 'nativescript-permissions';\n\ndeclare var android: any;\nconst RECORD_AUDIO = android.Manifest.permission.RECORD_AUDIO;\n\nexport class RecordModel extends Observable implements IRecordModel {\n\n  // available events to listen to\n  private _events: IRecordEvents;\n\n  // target as an Observable\n  private _target$: Subject<number>;\n\n  // recorder \n  private _recorder: TNSRecorder;\n  // recorder options \n  private _options: AudioRecorderOptions;\n  // recorder mix meter handling\n  private _meterInterval: number;\n\n  // state\n  private _state: number = RecordState.readyToRecord;\n\n  // tmp file path\n  private _filePath: string;\n  // the final saved path to use \n  private _savedFilePath: string;\n\n  constructor() {\n    super();\n    this._setupEvents();\n\n    // prepare Observable as our target\n    this._target$ = new Subject();\n\n    // create recorder\n    this._recorder = new TNSRecorder();\n this._filePath = documentsFilePath(`recording-${Date.now()}.m4a`);\n this._options = {\n      filename: this._filePath,\n      format: android.media.MediaRecorder.OutputFormat.MPEG_4,\n      encoder: android.media.MediaRecorder.AudioEncoder.AAC,\n      metering: true, // critical to feed our waveform view\n infoCallback: (infoObject) => {\n        // just log for now\n        console.log(JSON.stringify(infoObject));\n },\n errorCallback: (errorObject) => {\n console.log(JSON.stringify(errorObject));\n }\n };\n  }\n\n  public get events(): IRecordEvents {\n    return this._events;\n  }\n\n  public get target() {\n    return this._target$;\n  }\n\n  public get recorder(): any {\n    return this._recorder;\n  }\n\n  public get audioFilePath(): string {\n    return this._filePath;\n  }\n\n  public get state(): number {\n    return this._state;\n  }\n\n  public set state(value: number) {\n    this._state = value;\n    this._emitEvent(this._events.stateChange, this._state);\n  }\n\n  public get savedFilePath() {\n    return this._savedFilePath;\n  }\n\n  public set savedFilePath(value: string) {\n    this._savedFilePath = value;\n    if (this._savedFilePath)\n      this.state = RecordState.saved;\n  }\n\n  public toggleRecord() {\n    if (this._state !== RecordState.recording) {\n      // just force ready to record\n      // when coming from any state other than recording\n      this.state = RecordState.readyToRecord;\n    }\n\n    switch (this._state) {\n      case RecordState.readyToRecord:\n        if (this._hasPermission()) {\n this._recorder.start(this._options).then((result) => {\n this.state = RecordState.recording;\n this._initMeter();\n }, (err) => {\n this._resetMeter();\n });\n } else {\n permissions.requestPermission(RECORD_AUDIO).then(() => {\n            // simply engage again\n this.toggleRecord();\n }, (err) => {\n console.log('permissions error:', err);\n });\n }\n        break;\n      case RecordState.recording:\n        this._resetMeter();\n        this._recorder.stop();\n        this.state = RecordState.readyToPlay;\n        break;\n    }\n  }\n\n  public togglePlay() {\n    if (this._state === RecordState.readyToPlay) {\n      this.state = RecordState.playing;\n    } else {\n      this.stopPlayback();\n    }\n  }\n\n  public stopPlayback() {\n    if (this.state !== RecordState.recording) {\n      this.state = RecordState.readyToPlay;\n    }\n  }\n\n  public save() {\n    // With Android, filePath will be the same, just make it final\n    this.savedFilePath = this._filePath;\n  }\n\n  public dispose() {\n    if (this.state === RecordState.recording) {\n this._recorder.stop();\n }\n this._recorder.dispose();\n  }\n\n  public finish() {\n    this.state = RecordState.finish;\n  }\n\n  private _initMeter() {\n this._resetMeter();\n this._meterInterval = setInterval(() => {\n let meters = this.recorder.getMeters();\n this._target$.next(meters);\n }, 200); // use 50 for production - perf is better on devices\n }\n\n private _resetMeter() {\n if (this._meterInterval) {\n clearInterval(this._meterInterval);\n this._meterInterval = undefined;\n }\n }\n\n private _hasPermission() {\n return permissions.hasPermission(RECORD_AUDIO);\n }\n\n  private _emitEvent(eventName: string, data?: any) {\n    let event = {\n      eventName,\n      data,\n      object: this\n    };\n    this.notify(event);\n  }\n\n  private _setupEvents() {\n    this._events = {\n      stateChange: 'stateChange'\n    };\n  }\n}\n```", "```js\ntns plugin add nativescript-permissions\n```", "```js\n<uses-permission android:name=\"android.permission.READ_EXTERNAL_STORAGE\"/>\n<uses-permission android:name=\"android.permission.WRITE_EXTERNAL_STORAGE\"/>\n<uses-permission android:name=\"android.permission.INTERNET\"/>\n<uses-permission android:name=\"android.permission.RECORD_AUDIO\"/>\n```", "```js\nimport { View } from 'ui/core/view';\n\nexport type WaveformType = 'mic' | 'file';\n\nexport interface IWaveformModel {\n  readonly target: any;\n  dispose(): void;\n}\n\nexport interface IWaveform extends View {\n  type: WaveformType;\n  model: IWaveformModel;\n  createNativeView(): any;\n  initNativeView(): void;\n  disposeNativeView(): void;\n}\n```", "```js\n...\nimport { IWaveform, IWaveformModel, WaveformType } from './waveform-common';\n\nexport class Waveform extends View implements IWaveform {\n  ...\n```", "```js\ntsc app/modules/shared/native/waveform.ts references.d.ts -d true --lib es6,dom,es2015.iterable --target es5\n```", "```js\nimport { View } from 'ui/core/view';\nexport declare type WaveformType = 'mic' | 'file';\nexport interface IWaveformModel {\n  readonly target: any;\n  dispose(): void;\n}\nexport interface IWaveform extends View {\n  type: WaveformType;\n  model: IWaveformModel;\n  createNativeView(): any;\n  initNativeView(): void;\n  disposeNativeView(): void;\n}\nexport declare class Waveform extends View implements IWaveform {}\n```", "```js\nimport { View } from 'ui/core/view';\nimport { Color } from 'color';\nimport { IWaveform, IWaveformModel, WaveformType } from './common';\n\nexport class Waveform extends View implements IWaveform {\n  private _model: IWaveformModel;\n  private _type: WaveformType;\n\n  public set type(value: WaveformType) {\n    this._type = value;\n  }\n\n  public get type() {\n    return this._type;\n  }\n\n  public set model(value: IWaveformModel) {\n    this._model = value;\n  }\n\n  public get model() {\n    return this._model;\n  }\n\n  createNativeView() {\n    switch (this.type) {\n      case 'mic':\n        // TODO: this.nativeView = ?\n        break;\n      case 'file':\n        // TODO: this.nativeView = ?\n        break;\n    }\n    return this.nativeView;\n  }\n\n  initNativeView() {\n    // TODO\n  }\n\n  disposeNativeView() {\n    if (this.model && this.model.dispose) this.model.dispose();\n  }\n}\n```", "```js\n{\n  \"name\": \"android-waveform-libs\",\n  \"version\": \"1.0.0\",\n  \"nativescript\": {\n    \"platforms\": {\n      \"android\": \"3.0.0\"\n    }\n  }\n}\n```", "```js\ntns plugin add android-waveform-libs\n```", "```js\nimport { View } from 'ui/core/view';\nimport { Color } from 'color';\nimport { Subscription } from 'rxjs/Subscription';\nimport { IWaveform, IWaveformModel, WaveformType } from './common';\nimport { screen } from 'platform';\n\ndeclare var com;\ndeclare var android;\nconst GLSurfaceView = android.opengl.GLSurfaceView;\nconst AudioRecord = android.media.AudioRecord;\n\n// Horizon recorder waveform\n// https://github.com/Yalantis/Horizon\nconst Horizon = com.yalantis.waves.util.Horizon;\n// various recorder settings\nconst RECORDER_SAMPLE_RATE = 44100;\nconst RECORDER_CHANNELS = 1;\nconst RECORDER_ENCODING_BIT = 16;\nconst RECORDER_AUDIO_ENCODING = 3;\nconst MAX_DECIBELS = 120;\n\n// Semantive waveform for files\n// https://github.com/Semantive/waveform-android\nconst WaveformView = com.semantive.waveformandroid.waveform.view.WaveformView;\nconst CheapSoundFile = com.semantive.waveformandroid.waveform.soundfile.CheapSoundFile;\nconst ProgressListener = com.semantive.waveformandroid.waveform.soundfile.CheapSoundFile.ProgressListener;\n\nexport class Waveform extends View implements IWaveform {\n  private _model: IWaveformModel;\n  private _type: WaveformType;\n  private _initialized: boolean;\n private _horizon: any;\n private _javaByteArray: Array<any>;\n private _waveformFileView: any;\n private _sub: Subscription;\n\n  public set type(value: WaveformType) {\n    this._type = value;\n  }\n\n  public get type() {\n    return this._type;\n  }\n\n  public set model(value: IWaveformModel) {\n    this._model = value;\n    this._initView();\n  }\n\n  public get model() {\n    return this._model;\n  }\n\n  createNativeView() {\n    switch (this.type) {\n      case 'mic':\n        this.nativeView = new GLSurfaceView(this._context);\n this.height = 200; // GL view needs height\n        break;\n      case 'file':\n        this.nativeView = new WaveformView(this._context, null);\n this.nativeView.setSegments(null);\n this.nativeView.recomputeHeights(screen.mainScreen.scale);\n\n        // disable zooming and touch events\n this.nativeView.mNumZoomLevels = 0;\n this.nativeView.onTouchEvent = function (e) { return false; }\n        break;\n    }\n    return this.nativeView;\n  }\n\n  initNativeView() {\n    this._initView();\n  }\n\n  disposeNativeView() {\n    if (this.model && this.model.dispose) this.model.dispose();\n    if (this._sub) this._sub.unsubscribe();\n  }\n\n  private _initView() {\n    if (!this._initialized && this.nativeView && this.model) {\n      if (this.type === 'mic') {\n        this._initialized = true;\n this._horizon = new Horizon(\n this.nativeView,\n new Color('#000').android,\n RECORDER_SAMPLE_RATE,\n RECORDER_CHANNELS,\n RECORDER_ENCODING_BIT\n );\n\n this._horizon.setMaxVolumeDb(MAX_DECIBELS);\n let bufferSize = 2 * AudioRecord.getMinBufferSize(\n RECORDER_SAMPLE_RATE, RECORDER_CHANNELS, RECORDER_AUDIO_ENCODING);\n this._javaByteArray = Array.create('byte', bufferSize);\n\n this._sub = this._model.target.subscribe((value) => {\n this._javaByteArray[0] = value;\n this._horizon.updateView(this._javaByteArray);\n });\n      } else {\n        let soundFile = CheapSoundFile.create(this._model.target, \n new ProgressListener({\n reportProgress: (fractionComplete: number) => {\n console.log('fractionComplete:', fractionComplete);\n return true;\n }\n }));\n\n setTimeout(() => {\n this.nativeView.setSoundFile(soundFile);\n this.nativeView.invalidate();\n }, 0);\n      }\n    }\n  }\n}\n```", "```js\nthis.nativeView = new GLSurfaceView(this._context);\nthis.height = 200; // GL view needs height\n```", "```js\nupdateView(byte[] buffer)\n```", "```js\nlet bufferSize = 2 * AudioRecord.getMinBufferSize(\n  RECORDER_SAMPLE_RATE, RECORDER_CHANNELS, RECORDER_AUDIO_ENCODING);\nthis._javaByteArray = Array.create('byte', bufferSize);\n```", "```js\nthis._sub = this._model.target.subscribe((value) => {\n  this._javaByteArray[0] = value;\n  this._horizon.updateView(this._javaByteArray);\n});\n```"]