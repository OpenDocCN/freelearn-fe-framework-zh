- en: '8'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '8'
- en: Making Sure Customers Find You with Search Engine Optimization
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过搜索引擎优化确保客户能找到你
- en: When we optimized the performance of our blog in the previous chapter, you may
    have noticed that the Lighthouse report also includes a **Search Engine Optimization**
    (**SEO**) score, which our app scored relatively low on. This score tells us how
    optimized our app is for being indexed properly and found by search engines such
    as Google or Bing. After successfully developing a working blog app, of course,
    we want our blog to be found by users. In this chapter, we are going to learn
    the basics of SEO and how to optimize the SEO score for our React application.
    Then, we are going to learn how to create meta tags for easier integration on
    various social media sites.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中优化我们博客的性能时，您可能已经注意到Lighthouse报告还包括一个**搜索引擎优化**（**SEO**）得分，我们的应用程序在这个得分上相对较低。这个得分告诉我们我们的应用程序在正确索引和被搜索引擎如Google或Bing找到方面优化得有多好。当然，在成功开发了一个工作的博客应用程序之后，我们希望我们的博客能被用户找到。在本章中，我们将学习SEO的基础知识以及如何优化我们的React应用程序的SEO得分。然后，我们将学习如何创建元标签，以便更容易地在各种社交媒体网站上集成。
- en: 'In this chapter, we are going to cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Optimizing an application for search engines
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化应用程序以适应搜索引擎
- en: Improving social media embeds
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 改进社交媒体嵌入
- en: Technical requirements
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: Before we start, please install all requirements from [*Chapter 1*](B19385_01.xhtml#_idTextAnchor016)*,
    Preparing For Full-Stack Development*, and [*Chapter 2*](B19385_02.xhtml#_idTextAnchor028)*,
    Getting to Know Node.js* *and MongoDB*.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，请从[*第1章*](B19385_01.xhtml#_idTextAnchor016)*，准备全栈开发*和[*第2章*](B19385_02.xhtml#_idTextAnchor028)*，了解Node.js*和*MongoDB*中安装所有要求。
- en: The versions listed in those chapters are the ones used in the book. While installing
    a newer version should not be an issue, please note that certain steps might work
    differently on a newer version. If you are having an issue with the code and steps
    provided in this book, please try using the versions mentioned in *Chapters 1*
    and *2*.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 那些章节中列出的版本是书中使用的版本。虽然安装较新版本不应成问题，但请注意，某些步骤在较新版本上可能工作方式不同。如果您在这本书提供的代码和步骤上遇到问题，请尝试使用*第1章*和*第2章*中提到的版本。
- en: 'You can find the code for this chapter on GitHub: [https://github.com/PacktPublishing/Modern-Full-Stack-React-Projects/tree/main/ch8](https://github.com/PacktPublishing/Modern-Full-Stack-React-Projects/tree/main/ch8).'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在GitHub上找到本章的代码：[https://github.com/PacktPublishing/Modern-Full-Stack-React-Projects/tree/main/ch8](https://github.com/PacktPublishing/Modern-Full-Stack-React-Projects/tree/main/ch8)。
- en: 'The CiA video for this chapter can be found at: [https://youtu.be/1xN3l0MMTbY](https://youtu.be/1xN3l0MMTbY)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的CiA视频可以在以下网址找到：[https://youtu.be/1xN3l0MMTbY](https://youtu.be/1xN3l0MMTbY)
- en: If you cloned the full repository for the book, Husky may not find the `.git`
    directory when running `npm install`. In that case, just run `git init` in the
    root of the corresponding chapter folder.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您克隆了本书的完整仓库，Husky在运行`npm install`时可能找不到`.git`目录。在这种情况下，只需在相应章节文件夹的根目录下运行`git
    init`。
- en: Optimizing an application for search engines
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化应用程序以适应搜索引擎
- en: Before we get started optimizing our app for search engines, let’s briefly learn
    how search engines work. Search engines work by storing information about websites
    in an index. The **index** contains the location, content, and meta information
    of websites. Adding or updating pages in the index is called indexing and done
    by a crawler. A **crawler** is an automated software that fetches websites and
    indexes them. It is called a crawler because it follows further links on the website
    to find more websites. More advanced crawlers, such as the **Googlebot**, can
    also detect whether JavaScript is required to render the contents of a website
    and even render it.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始优化我们的应用程序以适应搜索引擎之前，让我们简要了解搜索引擎是如何工作的。搜索引擎通过在索引中存储有关网站的信息来工作。**索引**包含网站的地址、内容和元信息。在索引中添加或更新页面称为索引，由爬虫完成。**爬虫**是一种自动软件，它抓取网站并将它们索引。它被称为爬虫，因为它会跟随网站上的进一步链接以找到更多网站。更高级的爬虫，如**Googlebot**，还可以检测是否需要JavaScript来渲染网站的页面内容，甚至可以渲染它。
- en: 'The following graphic visualizes how a search engine crawler works:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图形展示了搜索引擎爬虫的工作原理：
- en: '![Figure 8.1 – Visualization of how a search engine crawler works](img/B19385_08_1.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![图8.1 – 搜索引擎爬虫工作原理的可视化](img/B19385_08_1.jpg)'
- en: Figure 8.1 – Visualization of how a search engine crawler works
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1 – 搜索引擎爬虫工作原理的可视化
- en: As we can see, a search crawler has a queue containing URLs that it needs to
    crawl and index. It then visits the URLs one by one, fetches the HTML and, if
    it is an advanced crawler, detects whether it needs to execute JavaScript to render
    the content. In that case, the URL is added to a render queue and the rendered
    HTML is passed back into the crawler later. Then, the crawler extracts all the
    links to other pages and adds them to the queue. Finally, the parsed content is
    added to the index.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，一个搜索爬虫有一个包含它需要爬取和索引的URL的队列。然后，它逐个访问这些URL，获取HTML，如果它是一个高级爬虫，它会检测是否需要执行JavaScript来渲染内容。在这种情况下，URL会被添加到渲染队列中，渲染后的HTML稍后会被传递回爬虫。然后，爬虫提取所有指向其他页面的链接并将它们添加到队列中。最后，解析后的内容被添加到索引中。
- en: To see whether a website is already indexed by a search engine, most search
    engines provide a `site:` operator, which can be used to check whether a URL is
    already indexed by it. For example, `site:wikipedia.org` shows various URLs on
    Wikipedia that are already indexed. If your website is not indexed yet, you can
    submit it to tools such as the **Google Search Console**. The Google Search Console
    also has a detailed overview of the indexing status and any problems with indexing.
    However, it is not necessary to submit our site for it to be found, because most
    search engines automatically crawl the web and will eventually find our website.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看一个网站是否已经被搜索引擎索引，大多数搜索引擎都提供了一个 `site:` 操作符，它可以用来检查一个URL是否已经被它索引。例如，`site:wikipedia.org`
    会显示维基百科上已经索引的各种URL。如果你的网站还没有被索引，你可以将其提交给像**Google Search Console**这样的工具。Google
    Search Console 还有一个关于索引状态和索引问题的详细概述。然而，为了使网站被发现，并不需要提交我们的网站，因为大多数搜索引擎会自动爬取网络，最终会发现我们的网站。
- en: If your website still does not get indexed, this might be because it is improperly
    configured. First, you need to create a `robots.txt` file to specify whether search
    engines are allowed to crawl parts of your website, and which parts they are allowed
    to crawl.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的网站仍然没有被索引，这可能是因为它配置不当。首先，你需要创建一个`robots.txt`文件来指定搜索引擎是否允许爬取你的网站的部分，以及允许爬取哪些部分。
- en: Note
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The **robots.txt** should not be used to hide web pages from Google search results.
    Instead, it is used to reduce traffic from crawlers on unimportant or similar
    pages. If you want to completely hide web pages from Google search results, either
    password-protect them, or use the **noindex** meta tag.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**robots.txt**不应用于从Google搜索结果中隐藏网页。相反，它用于减少对不重要或类似页面的爬虫流量。如果你想要完全从Google搜索结果中隐藏网页，要么对它们进行密码保护，要么使用**noindex**元标签。'
- en: Next, you need to make sure the contents of your website are visible to the
    crawler. Server-side rendering can help here by allowing crawlers to view the
    contents of your website without running JavaScript. Additionally, adding meta
    information using special HTML tags helps crawlers to get additional information
    about your website. For small websites, pages need to be linked properly or add
    a manual sitemap. For larger websites, such as a blog with many posts, a sitemap
    should always be defined. Finally, having good performance, fast load times, and
    a good user experience makes your website rank higher on search engines.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你需要确保你的网站内容对爬虫可见。服务器端渲染可以通过允许爬虫在不运行JavaScript的情况下查看你的网站内容来帮助这里。此外，使用特殊HTML标签添加元信息可以帮助爬虫获取有关你的网站的更多信息。对于小型网站，页面需要正确链接或添加手动网站地图。对于大型网站，例如拥有许多文章的博客，应该始终定义网站地图。最后，良好的性能、快速的加载时间和良好的用户体验可以使你的网站在搜索引擎中排名更高。
- en: We have already added server-side rendering to speed up crawling by serving
    content immediately without relying on JavaScript to render it. Now, let’s further
    optimize our app for search engines. We start by creating a `robots.txt` file.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经添加了服务器端渲染来通过立即提供服务内容而不依赖于JavaScript来渲染它来加速爬取。现在，让我们进一步优化我们的应用程序以适应搜索引擎。我们首先创建一个`robots.txt`文件。
- en: Creating a robots.txt file
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建robots.txt文件
- en: 'First, let’s ensure that crawlers are explicitly allowed to access our app
    and index all pages on it. To do so, we need to create a `robots.txt` file, which
    crawlers will read to find out which pages they are allowed to access (if any).
    Follow these steps to create a `robots.txt` file that allows access for all crawlers
    to all pages:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们确保爬虫明确允许访问我们的应用程序并索引其上的所有页面。为此，我们需要创建一个`robots.txt`文件，爬虫会读取该文件以找出它们允许访问的页面（如果有）。按照以下步骤创建一个允许所有爬虫访问所有页面的`robots.txt`文件：
- en: 'Copy the **ch7** folder to a new **ch8** folder, as follows:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将**ch7**文件夹复制到一个新的**ch8**文件夹，如下所示：
- en: '[PRE0]'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Open the **ch8** folder in VS Code.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开VS Code中的**ch8**文件夹。
- en: Create a new **public/robots.txt** file in the root of our project.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在项目的根目录中创建一个新的**public/robots.txt**文件。
- en: 'Open the newly created file and enter the following contents to allow all crawlers
    to index all pages:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开新创建的文件，并输入以下内容以允许所有爬虫索引所有页面：
- en: '[PRE1]'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The `robots.txt` works by defining blocks, each block being defined by matching
    a user agent. The user agent can match various crawlers, such as `Googlebot` for
    Google, or you can use `*` to match all crawlers. After the user agent, one or
    multiple `Allow` and/or `Disallow` statements can be made, that decide which paths
    a crawler is allowed or not allowed to access. In our case, we are allowing access
    to all paths. Additionally, a `Sitemap` can be specified, but we’ll see more on
    that later in the *Creating a* *sitemap* subsection.
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`robots.txt`通过定义块来工作，每个块由匹配用户代理来定义。用户代理可以匹配各种爬虫，例如Google的`Googlebot`，或者您可以使用`*`来匹配所有爬虫。在用户代理之后，可以做出一个或多个`Allow`和/或`Disallow`语句，这些语句决定爬虫是否允许访问某些路径。在我们的情况下，我们允许访问所有路径。此外，可以指定一个`Sitemap`，但我们将稍后在*创建一个*
    *sitemap* 子部分中了解更多。'
- en: 'Open a Terminal pane and start the frontend by running the following command:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的终端窗口，通过运行以下命令启动前端：
- en: '[PRE2]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Open another Terminal pane and start the backend by running the following commands:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开另一个终端窗口，通过运行以下命令启动后端：
- en: '[PRE3]'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Go to **http://localhost:5173/robots.txt** in your browser to see the **robots.txt**
    file being served properly.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在您的浏览器中转到**http://localhost:5173/robots.txt**以查看正确提供的服务**robots.txt**文件。
- en: Now that we have successfully allowed crawlers to access our app, we should
    improve our URL structure. Let’s do that by creating separate pages for each post.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经成功允许爬虫访问我们的应用，我们应该改进我们的URL结构。让我们通过为每篇帖子创建单独的页面来实现这一点。
- en: Creating separate pages for posts
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为帖子创建单独的页面
- en: 'At the moment, it is not possible to view only a single post in our blog app,
    we can only view the list of all posts. That is not good for SEO, as it means
    a search engine will always link to the index page, which might already contain
    different articles than what the user was searching for. Let’s refactor our app
    a bit to only show post titles and authors on the main page, and then link to
    separate pages for each blog post:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，在我们的博客应用中无法仅查看单个帖子，我们只能查看所有帖子的列表。这对SEO来说不好，因为它意味着搜索引擎总是会链接到索引页面，而这个页面可能已经包含与用户搜索内容不同的文章。让我们对我们的应用进行一点重构，只显示主页上的帖子标题和作者，然后为每篇博客帖子链接到单独的页面：
- en: 'Edit **src/components/Post.jsx** to allow displaying a single full post while
    displaying a smaller version of the post in the list, with a link to the full
    version. First, we import the **Link** component from **react-router-dom**:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑**src/components/Post.jsx**以允许在列表中显示帖子的小版本的同时显示单个完整帖子，并提供到完整版本的链接。首先，我们从**react-router-dom**导入**Link**组件：
- en: '[PRE4]'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Then, we add an **_id** prop and a **fullPost** prop to the **Post** component.
    The **fullPost** prop will be set to **false** by default (when displayed in the
    post list) and set to **true** when using it in the single-post page:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们在**Post**组件中添加一个**_id**属性和一个**fullPost**属性。**fullPost**属性默认设置为**false**（当在帖子列表中显示时）并在使用它时在单篇帖子页面中设置为**true**：
- en: '[PRE5]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We make some adjustments to the component to show a link to the single-post
    page if we are not on a single-post page yet:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们对组件进行一些调整，以便在尚未在单篇帖子页面时显示到单篇帖子页面的链接：
- en: '[PRE6]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Additionally, we only show the contents of the blog post on a single-post page,
    and adjust the spacing of the author info accordingly:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此外，我们只在单篇帖子页面上显示博客帖子的内容，并相应地调整作者信息的间距：
- en: '[PRE7]'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Adjust the prop types to add the newly defined props:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调整属性类型以添加新定义的属性：
- en: '[PRE8]'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Edit **src/api/posts.js** and add a new function to get a single post by **id**:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑**src/api/posts.js**并添加一个新函数，通过**id**获取单个帖子：
- en: '[PRE9]'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Create a new **src/pages/ViewPost.jsx** file, and start by importing all the
    components and functions that we are going to need:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的**src/pages/ViewPost.jsx**文件，并首先导入我们将需要的所有组件和函数：
- en: '[PRE10]'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Then, define a component that accepts a **postId** as props:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，定义一个组件，该组件接受**postId**作为属性：
- en: '[PRE11]'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'In the component, we use a query hook to fetch a single post by **id**:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在组件中，我们使用查询钩子通过**id**获取单个帖子：
- en: '[PRE12]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Next, render the header and a link back to the main page:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，渲染页眉和返回主页的链接：
- en: '[PRE13]'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Then, if we managed to fetch a post with the given ID, render a post with the
    **fullPost** prop set. Otherwise, we show a **not** **found** message:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，如果我们成功获取了具有给定ID的帖子，就使用设置**fullPost**属性的帖子进行渲染。否则，我们显示**未找到**的信息：
- en: '[PRE14]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Lastly, define the prop types for the **ViewPost** component:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，定义**ViewPost**组件的prop类型：
- en: '[PRE15]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Edit **src/routes.jsx** and import the **ViewPost** component and the **getPostById**
    function (for server-side rendering):'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑**src/routes.jsx**并导入**ViewPost**组件和**getPostById**函数（用于服务器端渲染）：
- en: '[PRE16]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Define a new **/posts/:postId** route for viewing a single post. In the loader,
    we fetch the single blog post and an author, if it has one. We then return the
    dehydrated state and the post ID:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个新的**/posts/:postId**路由以查看单个文章。在加载器中，我们获取单个博客文章和作者（如果有）。然后返回脱水的状态和文章ID：
- en: '[PRE17]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Define a **Component** method for the route, where we get **dehydratedState**
    and **postId** and pass them on to the **ViewPost** component, as follows:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为路由定义一个**组件**方法，其中我们获取**dehydratedState**和**postId**，并将它们传递给**ViewPost**组件，如下所示：
- en: '[PRE18]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Go to **http://localhost:5173/** in your browser and you will see that all
    blog posts in the list now have a link in their title. Click on the link to see
    the full blog post, as shown in the following screenshot:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在您的浏览器中访问**http://localhost:5173/**，您会看到列表中的所有博客文章标题现在都有一个链接。点击链接查看完整的博客文章，如下面的截图所示：
- en: '![Figure 8.2 – Viewing a single blog post on a separate page](img/B19385_08_2.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![图8.2 – 在单独的页面上查看单个博客文章](img/B19385_08_2.jpg)'
- en: Figure 8.2 – Viewing a single blog post on a separate page
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.2 – 在单独的页面上查看单个博客文章
- en: Now our blog app is already much more organized, as we do not see the full contents
    of all blog posts on the main page. We only see the title and author now and can
    then decide whether the article is interesting to us or not. Furthermore, a search
    engine can provide separate entries for each blog post, making it easier to find
    posts on our app. There is still room for improvement with the URL structure though,
    as it currently only contains the post ID. Let’s introduce more meaningful URLs
    in the next step.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的博客应用已经组织得更好了，因为我们不再在主页上看到所有博客文章的完整内容。我们现在只看到标题和作者，然后可以决定这篇文章是否对我们感兴趣。此外，搜索引擎可以为每个博客文章提供单独的条目，这使得在我们的应用中查找文章更容易。不过，在URL结构方面仍有改进的空间，因为它目前只包含文章ID。让我们在下一步中引入更有意义的URL。
- en: Creating meaningful URLs (slugs)
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建有意义的URL（slugs）
- en: 'Websites often put keywords in the URLs to make it easier for users to see
    what they will be opening just by looking at the URL. Keywords in URLs are also
    a ranking factor for search engines, albeit a not-so-strong one. The strongest
    one is always good content. Nevertheless, having a good URL structure improves
    the user experience. For example, if the link is `/posts/64a42dfd6a7b7ab47009f5e3/making-sure-customers-find-you-with-search-engine-optimization`
    instead of just `/posts/64a42dfd6a7b7ab47009f5e3`, it is already clear from the
    URL alone what content they will find on the page. Such keywords in the URL are
    called a URL slug, named after “slugs” in journalism, which refers to using short
    descriptions of articles as internal names. Let’s get started introducing slugs
    on our post pages:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 网站通常在URL中放置关键词，以便用户只需查看URL就能更容易地看到他们将要打开的内容。URL中的关键词也是搜索引擎的排名因素，尽管不是那么强烈。最强的因素始终是优质内容。尽管如此，良好的URL结构可以提高用户体验。例如，如果链接是`/posts/64a42dfd6a7b7ab47009f5e3/making-sure-customers-find-you-with-search-engine-optimization`而不是仅仅`/posts/64a42dfd6a7b7ab47009f5e3`，那么仅从URL本身就可以清楚地知道他们将在页面上找到什么内容。这样的关键词在URL中被称为URL
    slug，这个名字来源于新闻业中的“slugs”，指的是使用文章的简短描述作为内部名称。让我们开始在我们的文章页面上引入slugs：
- en: 'Edit **src/routes.jsx** and adjust the path to allow for optionally including
    a slug:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑**src/routes.jsx**并调整路径以允许可选地包含一个slug：
- en: '[PRE19]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Note
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: We are not doing any checks on whether the slug is correct or not. In fact,
    this is not really necessary, and many pages do not do this. As long as we have
    a correct ID, we can render the blog post. We only need to make sure that the
    links to the page all include the correct slug. However, we could additionally
    add a **<link>** element with the **rel="canonical"** attribute to a page, specifying
    the canonical page with the correct slug. This would tell crawlers not to index
    duplicate pages when incorrect slugs are used.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有对slug是否正确进行检查。实际上，这并不是真的必要，许多页面都不这样做。只要我们有正确的ID，我们就可以渲染博客文章。我们只需要确保指向页面的所有链接都包含正确的slug。然而，我们还可以添加一个带有**rel="canonical"**属性的**<link>**元素到页面中，指定带有正确slug的规范页面。这将告诉爬虫在使用不正确的slug时不要索引重复页面。
- en: 'In the root of our project, install the **slug** npm package, which contains
    a function to properly slugify a title:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们项目的根目录中安装**slug** npm包，它包含一个用于正确slugify标题的函数：
- en: '[PRE20]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Edit **src/components/Post.jsx** and import the **slug** function:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑 **src/components/Post.jsx** 并导入 **slug** 函数：
- en: '[PRE21]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Then, adjust the link to the blog post by adding the slug, as follows:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，通过添加slug调整博客帖子的链接，如下所示：
- en: '[PRE22]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Now, when we open a link from the list, the URL will look as follows:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，当我们从列表中打开一个链接时，URL将如下所示：
- en: '[PRE23]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Now we have human readable URLs for our blog posts! However, you might have
    noticed that the title is still **Vite + React** on all pages of our app. Let’s
    change that now by introducing dynamic titles and including the blog post title
    in the page title.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们为我们的博客帖子有了可读的URL！然而，你可能已经注意到，在我们的应用的所有页面上标题仍然是 **Vite + React**。现在让我们通过引入动态标题并在页面标题中包含博客帖子标题来改变这一点。
- en: Adding dynamic titles
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 添加动态标题
- en: 'The title of a page is even more important for SEO than keywords in the URL,
    as that is the title that will be shown in the search results in most cases. So,
    we should choose our title wisely, and if we have dynamic content (like in our
    blog), we should also dynamically adjust the title to fit the content. We can
    use the React Helmet library to facilitate changes in the `<head>` section of
    the HTML document. This library allows us to render a special `Helmet` component.
    The children of this component will replace existing tags in the `<head>` section.
    Follow these steps to use React Helmet to dynamically set the title:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 页面的标题对于SEO的重要性甚至超过了URL中的关键词，因为这是在大多数情况下将在搜索结果中显示的标题。因此，我们应该明智地选择标题，如果我们有动态内容（如我们的博客），我们也应该动态调整标题以适应内容。我们可以使用
    React Helmet 库来简化 HTML 文档 `<head>` 部分的更改。这个库允许我们渲染一个特殊的 `Helmet` 组件。此组件的子元素将替换
    `<head>` 部分中现有的标签。按照以下步骤使用 React Helmet 动态设置标题：
- en: 'First of all, let’s change the general title of our app, as it is still **Vite
    + React**. Edit **index.html** in the root of our project and change the title.
    We are going to call our blog app **Full-Stack** **React Blog**:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们改变我们应用的一般标题，因为它仍然是 **Vite + React**。编辑我们项目的根目录下的 **index.html** 并更改标题。我们将把我们的博客应用命名为
    **Full-Stack** **React Blog**：
- en: '[PRE24]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'In the root of our project, install the **react-helmet-async** dependency to
    be able to dynamically change the title:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们项目的根目录中，安装 **react-helmet-async** 依赖项以便能够动态更改标题：
- en: '[PRE25]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Note
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: React Helmet Async is a fork of the original React Helmet that adds support
    for newer React versions.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: React Helmet Async 是原始 React Helmet 的分支，它增加了对较新 React 版本的支持。
- en: 'Edit **src/pages/ViewPost.jsx** and import the **Helmet** component from **react-helmet-async**:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑 **src/pages/ViewPost.jsx** 并从 **react-helmet-async** 中导入 **Helmet** 组件：
- en: '[PRE26]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Render the **Helmet** component and define the **<title>** tag inside it, as
    follows:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 渲染 **Helmet** 组件并在其中定义 **<title>** 标签，如下所示：
- en: '[PRE27]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Edit **src/pages/Blog.jsx** and import **Helmet**:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑 **src/pages/Blog.jsx** 并导入 **Helmet**：
- en: '[PRE28]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Then, reset the title to **Full-Stack React Blog** in the **Blog** component:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，在 **Blog** 组件中将标题重置为 **Full-Stack React Blog**：
- en: '[PRE29]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Edit **src/App.jsx** and import the **HelmetProvider**:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑 **src/App.jsx** 并导入 **HelmetProvider**：
- en: '[PRE30]'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Then, adjust the **App** component to render **HelmetProvider**:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，调整 **App** 组件以渲染 **HelmetProvider**：
- en: '[PRE31]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Click on a single post in the app and you will see that the title now updates
    to include the post title!
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在应用中点击单个帖子，你会看到标题现在更新为包括帖子标题！
- en: Now that we have successfully set a dynamic title, let’s pay some attention
    to other important information in the `<head>` section, the **meta tags**.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经成功设置了动态标题，让我们关注 `<head>` 部分中的其他重要信息，即 **meta标签**。
- en: Adding other meta tags
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 添加其他元标签
- en: Meta tags, as the name tells us, contain meta information about a page. Besides
    the title, we can set meta information such as a short description, or information
    on how the browser should render a website. In this section, we will cover the
    most important SEO-relevant meta tags, starting with the description meta tag.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 元标签，正如其名所示，包含有关页面元信息。除了标题外，我们还可以设置诸如简短描述或浏览器应该如何渲染网站等信息。在本节中，我们将介绍最重要的与SEO相关的元标签，从描述元标签开始。
- en: Description meta tag
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 描述元标签
- en: 'The description meta tag contains a short description of the contents of the
    page. Similarly to the title tag, we can also dynamically set this tag, as follows:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 描述元标签包含页面内容的简短描述。类似于标题标签，我们也可以动态设置此标签，如下所示：
- en: 'Edit **src/pages/Blog.jsx** and add the following generic description **<****meta>**
    tag:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑 **src/pages/Blog.jsx** 并添加以下通用的 **<meta>** 标签：
- en: '[PRE32]'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Now, let’s add a dynamic meta description tag for each blog post. The meta description
    should have between 50 and 160 characters, and since we do not have a short summary
    of our blog posts, let’s just use the full contents and truncate them after 160
    characters. Of course, it would be even better to let authors add a short summary
    when creating posts, but for simplicity, we just truncate the description here.
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，让我们为每篇博客文章添加一个动态的meta描述标签。meta描述应该有50到160个字符，由于我们没有博客文章的简短摘要，我们只需使用完整内容并在160个字符后截断。当然，如果作者在创建帖子时添加简短摘要会更好，但为了简单起见，我们在这里只截断描述。
- en: 'Edit the **src/pages/ViewPost.jsx** file and define a simple function to truncate
    a string:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑**src/pages/ViewPost.jsx**文件，并定义一个简单的函数来截断字符串：
- en: '[PRE33]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: We limit the string to 160 characters, and if it’s above 160, we truncate it
    to 157 characters and add three dots at the end.
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将字符串限制在160个字符以内，如果超过160个字符，我们将截断到157个字符，并在末尾添加三个点。
- en: 'Add the truncated content as a meta description tag to the **Helmet** component,
    as follows:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将截断的内容作为meta描述标签添加到**Helmet**组件中，如下所示：
- en: '[PRE34]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: After adding the description meta tag, let’s learn about other meta tags that
    could be used.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在添加了description元标签之后，让我们学习其他可能用到的元标签。
- en: Robots meta tag
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Robots元标签
- en: 'The `robots` meta tag tells crawlers whether and how they should crawl web
    pages. It can be used in addition to `robots.txt`, but we should only use it if
    we want to dynamically restrict the way a certain page is crawled. It looks as
    follows:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '`robots`元标签告诉爬虫它们是否以及如何爬取网页。它可以与`robots.txt`一起使用，但我们应该只在想要动态限制特定页面爬取方式时使用它。它看起来如下所示：'
- en: '[PRE35]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The `index` keyword tells crawlers to index the page, the `follow` keyword tells
    crawlers to crawl further links on the page. The `index` and `follow` keywords
    can be toggled off by using `noindex` and `nofollow`, respectively.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '`index`关键字告诉爬虫索引页面，`follow`关键字告诉爬虫爬取页面上的进一步链接。可以通过使用`noindex`和`nofollow`来关闭`index`和`follow`关键字。'
- en: Viewport meta tag
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Viewport元标签
- en: 'Another important meta tag to add is the viewport tag, which tells the browser
    (and crawlers) that your website is mobile friendly. See the following example
    of how the meta tag affects how pages are rendered on mobile:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个需要添加的重要元标签是viewport标签，它告诉浏览器（和爬虫）您的网站是移动友好的。以下是一个示例，说明元标签如何影响移动设备上页面的渲染方式：
- en: '![Figure 8.3 – A blog post rendering before and after adding the viewport meta
    tag](img/B19385_08_3.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![图8.3 – 添加viewport元标签前后博客文章的渲染效果](img/B19385_08_3.jpg)'
- en: Figure 8.3 – A blog post rendering before and after adding the viewport meta
    tag
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.3 – 添加viewport元标签前后博客文章的渲染效果
- en: 'Vite already added this meta tag automatically for us in the `index.html` template
    it provided. You can see it by looking at the `index.html` file:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: Vite已经在它提供的`index.html`模板中为我们自动添加了这个元标签。您可以通过查看`index.html`文件来看到它：
- en: '[PRE36]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: After learning about the viewport tag, we continue by learning about the charset
    meta tag.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在了解viewport标签之后，我们继续学习charset元标签。
- en: Charset meta tag
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Charset元标签
- en: 'The charset meta tag tells the browser and crawlers about the character encoding
    of the web page. Usually, you want to set this to UTF-8 to ensure all Unicode
    characters are rendered properly. Again, Vite already added this meta tag automatically
    for us:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: charset元标签告诉浏览器和爬虫关于网页的字符编码。通常，您希望将其设置为UTF-8，以确保所有Unicode字符都能正确渲染。同样，Vite已经为我们自动添加了这个元标签：
- en: '[PRE37]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Now that we have learned about the relevant meta tags, let’s move on to creating
    a sitemap, which helps crawlers find all the pages on our app more easily.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了相关的元标签，让我们继续创建一个网站地图，这有助于爬虫更容易地找到我们应用上的所有页面。
- en: Other relevant meta information
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 其他相关元信息
- en: 'There is additional meta information that can be relevant for a website, such
    as setting the language in the `<html>` tag, as follows:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 对于网站，可能还有其他相关的元信息，例如在`<html>`标签中设置语言，如下所示：
- en: '[PRE38]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Setting a favicon also improves the search snippet, which is what users see
    when deciding whether they should click on a link.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 设置favicon也可以提高搜索片段，这是用户在决定是否点击链接时看到的。
- en: Creating a sitemap
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建网站地图
- en: 'A sitemap contains a list of URLs that are part of an app, so that crawlers
    can easily detect new content and crawl the app more efficiently. It also makes
    sure that all content is found, which is especially important for content-based
    apps with a large number of pages/posts. Usually, sitemaps are provided in XML
    format. They are not mandatory for SEO, but will make it easier and faster for
    crawlers to pick up content on your app. As we have dynamic content on our blog
    app, we should also create a dynamic sitemap. Follow these steps to create a dynamic
    sitemap for our blog app:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 站点地图包含一个应用程序中所有URL的列表，这样爬虫可以轻松地检测新内容并更有效地爬取应用程序。它还确保所有内容都被找到，这对于拥有大量页面/帖子的基于内容的应用程序尤为重要。通常，站点地图以XML格式提供。它们对于SEO不是强制性的，但会使爬虫更容易、更快地抓取应用程序上的内容。由于我们的博客应用程序有动态内容，我们还应该创建一个动态的站点地图。按照以下步骤为我们的博客应用程序创建一个动态站点地图：
- en: 'First, we are going to need a base URL for our (deployed) frontend to prefix
    all paths on our sitemap with. For now, we are simply going to set this to our
    localhost URL, but in production, this environment variable should be changed
    to the proper base URL of the app. Edit **.env** in the root of our project and
    add a **FRONTEND_URL** environment variable:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要为我们的（已部署的）前端提供一个基础URL，以便将所有路径添加到我们的站点地图中。目前，我们只是将其设置为本地主机URL，但在生产环境中，这个环境变量应该更改为应用程序的正确基础URL。编辑项目根目录下的**.env**文件，并添加一个**FRONTEND_URL**环境变量：
- en: '[PRE39]'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Create a new **generateSitemap.js** file in the root of our project, start
    by importing the **slug** function and **dotenv**:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们项目的根目录下创建一个新的**generateSitemap.js**文件，首先导入**slug**函数和**dotenv**：
- en: '[PRE40]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Then, save the previously created environment variable in a **baseUrl** variable:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，将之前创建的环境变量保存在一个**baseUrl**变量中：
- en: '[PRE41]'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Now, define an **async** function to generate a sitemap. In this function,
    we start by fetching a list of blog posts, as we want each blog post to be part
    of the sitemap:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，定义一个**async**函数来生成站点地图。在这个函数中，我们首先获取一个博客帖子列表，因为我们希望每个博客帖子都成为站点地图的一部分：
- en: '[PRE42]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Next, we return a string containing the XML for the sitemap. We start by defining
    the XML header and a **<****urlset>** tag:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们返回一个包含站点地图XML的字符串。我们首先定义XML头和一个**<urlset>**标签：
- en: '[PRE43]'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Inside the **<urlset>** tag, we can use **<url>** tags with **<loc>** tags
    to link to various pages. We first list all the static pages:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**<urlset>**标签内部，我们可以使用带有**<loc>**标签的**<url>**标签来链接到各个页面。我们首先列出所有静态页面：
- en: '[PRE44]'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Then, we loop over all posts that we fetched from the backend and generate
    a **<url>** tag for each of them, constructing the URLs from the post ID and the
    slug:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们遍历从后端获取的所有帖子，并为每个帖子生成一个**<url>**标签，从帖子ID和缩略名构建URL：
- en: '[PRE45]'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'We can also optionally specify a **<lastmod>** tag, telling the crawler when
    the content was last modified:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以可选地指定一个**<lastmod>**标签，告诉爬虫内容最后修改的时间：
- en: '[PRE46]'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Lastly, we join all generated **<url>** tags together into a single string
    and close the **<****urlset>** tag:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将所有生成的**<url>**标签合并成一个单独的字符串，并关闭**<urlset>**标签：
- en: '[PRE47]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Now that we have a function to dynamically generate a sitemap, we still need
    to include a route to it in our server.
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在我们有一个动态生成站点地图的函数，我们仍然需要在我们的服务器中包含一个到它的路由。
- en: 'Edit **server.js** and import the **generateSitemap** function there:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑**server.js**文件，并在其中导入**generateSitemap**函数：
- en: '[PRE48]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Then, go to the first **app.use(''*'')** declaration inside the **createProdServer**
    function and check whether the URL is **/sitemap.xml**. If yes, generate the sitemap
    and return it as XML:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，转到**createProdServer**函数内部的第一个**app.use('*')**声明，检查URL是否为**/sitemap.xml**。如果是，则生成站点地图并将其作为XML返回：
- en: '[PRE49]'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Note
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: In a more sophisticated setup, we could cache the generated sitemap either on
    our Express server, our own web server, or a separate caching service.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在更复杂的设置中，我们可以在我们的Express服务器、我们自己的Web服务器或一个单独的缓存服务上缓存生成的站点地图。
- en: We do the same change as in the previous step for the second **app.use('*')**
    declaration inside the **createDevServer** function.
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于**createDevServer**函数内部的第二个**app.use('*')**声明，我们进行与上一步相同的更改。
- en: Restart the server and go to **http://localhost:5173/sitemap.xml** to see the
    sitemap being dynamically generated, with links to all created posts and their
    last modified timestamps.
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新启动服务器，并访问**http://localhost:5173/sitemap.xml**以查看动态生成的站点地图，其中包含所有创建的帖子及其最后修改的时间戳。
- en: 'We can now link to the sitemap in the **robots.txt** file. As an example, we
    are going to set the URL to localhost. In a production app, you would adjust this
    URL to point to the sitemap on the URL of the deployed application. Edit **public/robots.txt**
    and add the following line:'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在可以在**robots.txt**文件中链接到网站地图。例如，我们将设置 URL 为 localhost。在生产应用程序中，您将调整此 URL
    以指向部署应用程序的 URL。编辑**public/robots.txt**并添加以下行：
- en: '[PRE50]'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Now that we have successfully implemented measures to improve our app for search
    engines, let’s take a look at our SEO score in the Lighthouse report:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经成功实施了提高我们应用程序搜索引擎优化的措施，让我们来看看 Lighthouse 报告中的我们的 SEO 评分：
- en: '![Figure 8.4 – Our Lighthouse SEO score is now 100!](img/B19385_08_4.jpg)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.4 – 我们灯塔 SEO 评分现在为 100！](img/B19385_08_4.jpg)'
- en: Figure 8.4 – Our Lighthouse SEO score is now 100!
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.4 – 我们灯塔 SEO 评分现在为 100！
- en: As we can see, our SEO score is now 100 (from 91 before). This might only seem
    like a slight improvement, but the Lighthouse report only takes into account basic
    checks, such as having a title, description, viewport tag, and a `robots.txt`
    file. We have done much more to optimize the user experience for visitors and
    search engines, such as improving the URL structure and adding dynamic titles
    and descriptions.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，我们的 SEO 评分现在为 100（之前为 91）。这可能看起来只是轻微的改进，但 Lighthouse 报告只考虑基本检查，例如有标题、描述、viewport
    标签和 `robots.txt` 文件。我们已经做了更多工作来优化访客和搜索引擎的用户体验，例如改进 URL 结构和添加动态标题和描述。
- en: We could still further optimize our app by serving static assets via a **Content
    Delivery Network** (**CDN**) and using responsive images (serving images in different
    sizes to optimize performance on slower connections and avoid loading the full-size
    images). However, that is outside the scope of this book.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过通过**内容分发网络**（**CDN**）提供静态资源和使用响应式图片（为较慢的连接提供不同大小的图片以优化性能并避免加载全尺寸图片）来进一步优化我们的应用程序。然而，这超出了本书的范围。
- en: To wrap up this chapter, we are going to take a look at improving embeds on
    social media sites.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 为了总结本章，我们将探讨如何提高社交媒体网站上的嵌入。
- en: Improving social media embeds
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提高社交媒体嵌入
- en: We have already added the important meta tags for search engines. However, social
    media websites, such as Facebook and X (formerly Twitter), read additional meta
    tags to improve the embedding of your app on their sites and apps. Most social
    networks use a standard called Open Graph Meta Tags, which was originally created
    at Facebook. These tags can contain additional information on the type of page,
    a special title, the description, and an image for embedding the page on a social
    media website.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经添加了搜索引擎的重要元标签。然而，社交媒体网站，如 Facebook 和 X（前身为 Twitter），读取额外的元标签以改善您在他们的网站和应用程序上的应用程序嵌入。大多数社交网络使用一个称为
    Open Graph Meta Tags 的标准，最初由 Facebook 创建。这些标签可以包含有关页面类型、特殊标题、描述和嵌入社交媒体网站时使用的图像的附加信息。
- en: Open Graph meta tags
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Open Graph 元标签
- en: 'The **Open Graph** (**OG**) meta tags have four generic properties that every
    page can have:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '**Open Graph**（**OG**）元标签有四个通用的属性，每个页面都可以有：'
- en: '**og:type**: Describes the type of the page; specific types may have additional
    properties'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**og:type**: 描述页面的类型；特定类型可能有额外的属性'
- en: '**og:title**: Describes the title of the page as it should appear on embeds'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**og:title**: 描述页面在嵌入时应显示的标题'
- en: '**og:image**: An URL to an image that should be used for the embed'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**og:image**: 一个用于嵌入的图像的 URL'
- en: '**og:url**: An URL to a link that should be used for the embed'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**og:url**: 一个用于嵌入的链接的 URL'
- en: 'The `og:type` meta tag describes the type of content available on the page.
    It tells the social media sites how the embed should be formatted. Among others,
    the following values are possible:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '`og:type` 元标签描述了页面上的内容类型。它告诉社交媒体网站如何格式化嵌入。以下是一些可能的值：'
- en: '**website**: The default value, a basic embed'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**website**: 默认值，一个基本的嵌入'
- en: '**article**: This is for news and blog posts, and has additional parameters
    for **published_time**, **modified_time**, **author**, **section**, and **tag**'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**article**: 这是针对新闻和博客文章的，有额外的参数，如**发布时间**、**修改时间**、**作者**、**部分**和**标签**'
- en: '**profile**: For user profiles, with additional parameters for **first_name**,
    **last_name**, **username**, and **gender**'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**profile**: 对于用户资料，有额外的参数，如**名字**、**姓氏**、**用户名**和**性别**'
- en: '**book**: For books, with additional parameters for **author**, **isbn**, **release_date**,
    and **tag**'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**book**: 对于书籍，有额外的参数，如**作者**、**isbn**、**发布日期**和**标签**'
- en: '**music** types: This includes **music.song**, **music.album**, **music.playlist**,
    and **music.radio_station**, each of them having different additional parameters'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**音乐**类型：这包括**music.song**、**music.album**、**music.playlist**和**music.radio_station**，每个都有不同的附加参数'
- en: '**video** types: This includes **video.movie**, **video.episode**, **video.tv_show**,
    and **video.other**, each of them having different additional parameters'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**视频**类型：这包括**video.movie**、**video.episode**、**video.tv_show**和**video.other**，每个都有不同的附加参数'
- en: 'A full description of the OG meta tags and all possible values can be found
    on their official website: [https://ogp.me/](https://ogp.me/).'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: OG元标签的完整描述和所有可能的值可以在它们的官方网站上找到：[https://ogp.me/](https://ogp.me/)。
- en: Info
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 信息
- en: Most social media sites support OG meta tags for embeds. However, some websites,
    including X (formerly Twitter), have their own meta tags, which take priority
    over OG meta tags, if provided. X can still read OG meta tags though, so it is
    enough to only provide those.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数社交媒体网站都支持OG元标签用于嵌入。然而，一些网站，包括X（前身为Twitter），有自己的元标签，如果提供，则优先于OG元标签。尽管如此，X仍然可以读取OG元标签，所以只提供那些就足够了。
- en: Now, we are going to focus on the `article` type, as we are developing a blog
    application, so we can use this type to provide better embeds for the blog posts.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将关注`article`类型，因为我们正在开发一个博客应用程序，所以我们可以使用这个类型为博客文章提供更好的嵌入：
- en: Using the OG article meta tags
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用OG文章元标签
- en: 'As we have learned, the `article` type allows us to include meta information
    about the published time, modified time, and author of an article on our page.
    Let’s do this now for our single-post page:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所学的，`article`类型允许我们在页面上包含关于文章发布时间、修改时间和作者的信息。现在让我们为我们的单篇文章页面做这件事：
- en: 'Edit **src/pages/ViewPost.jsx** and import the **getUserInfo** API function,
    as we will need to resolve the author name for the corresponding meta tag:'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑**src/pages/ViewPost.jsx**并导入**getUserInfo** API函数，因为我们需要解析对应元标签的作者名称：
- en: '[PRE51]'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Inside the **ViewPost** component after we fetch the post, fetch the author
    name. We make sure to only do this call if the **post?.author** attribute exists
    by using the **enabled** option of the **useQuery** hook:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**ViewPost**组件中，在获取文章后，获取作者名称。我们确保只有当**post?.author**属性存在时才进行此调用，通过使用**useQuery**钩子的**enabled**选项：
- en: '[PRE52]'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Inside the **Helmet** component, we define the **og:type** tag as **article**
    and define the title, published time, and modified time:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**Helmet**组件内部，我们将**og:type**标签定义为**article**，并定义标题、发布时间和修改时间：
- en: '[PRE53]'
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Then, we set the **og:article:author** to the resolved username:'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将**og:article:author**设置为解析后的用户名：
- en: '[PRE54]'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Lastly, we loop through the tags (if there are none, we default to an empty
    array) and define a meta tag for each tag:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们遍历标签（如果没有标签，我们默认为空数组）并为每个标签定义一个元标签：
- en: '[PRE55]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Arrays in OG meta tags work by redefining the same property multiple times.
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: OG元标签中的数组通过多次重新定义相同的属性来工作。
- en: Now that we have successfully added meta tags, our blog app is optimized for
    search engines and social media sites!
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经成功添加了元标签，我们的博客应用程序已经针对搜索引擎和社交媒体网站进行了优化！
- en: Summary
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we first briefly learned how search engines work. Then, we
    created a `robots.txt` file, along with separate pages for each blog post, to
    better optimize our blog for search engines. Next, we created meaningful URLs
    (slugs) and set dynamic titles and meta tags. Then, we created a sitemap and evaluated
    the SEO score of our blog after all optimizations. Finally, we learned how social
    media embeds work and which meta tags can be used to improve embeds for articles,
    such as blog posts.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们首先简要了解了搜索引擎的工作原理。然后，我们创建了一个`robots.txt`文件，并为每个博客文章创建了单独的页面，以更好地优化我们的博客以适应搜索引擎。接下来，我们创建了有意义的URL（别名）并设置了动态标题和元标签。然后，我们在所有优化完成后创建了一个网站地图并评估了博客的SEO得分。最后，我们学习了社交媒体嵌入的工作原理以及哪些元标签可以用来改进文章的嵌入，例如博客文章。
- en: In the next chapter, [*Chapter 9*](B19385_09.xhtml#_idTextAnchor176)*, Implementing
    End-to-End Tests Using Playwright*, we are going to learn how to write end-to-end
    tests for our user interface by setting up Playwright. Then, we are going to write
    some frontend tests for our blog application.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章[第9章](B19385_09.xhtml#_idTextAnchor176)《使用Playwright实现端到端测试》中，我们将学习如何通过设置Playwright来编写用户界面的端到端测试。然后，我们将为我们的博客应用程序编写一些前端测试。
