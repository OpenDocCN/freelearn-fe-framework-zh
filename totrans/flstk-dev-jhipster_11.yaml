- en: Deploying with Docker Compose
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have generated the application and it is ready for production. In this chapter,
    we will focus on how to deploy the application using Docker Compose. We will also
    see the various options that JHipster provides for deployment, followed by how
    to deploy our registry and console alongside the application.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will look into:'
  prefs: []
  type: TYPE_NORMAL
- en: A short introduction to Docker Compose
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kickstarting Kubernetes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing OpenShift
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Explaining Rancher
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then we will discuss locally with JHipster Registry and JHipster Console
  prefs: []
  type: TYPE_NORMAL
- en: Introducing microservice deployment options
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The success of an application not only depends on how well we design it. It
    depends on how well we implement (deploy and maintain) it.
  prefs: []
  type: TYPE_NORMAL
- en: 'A well-designed microservice application in a low-availability environment
    is useless. So it is equally important to decide on a deployment strategy that
    increases its chances to succeed. When it comes to deployment, there is a plethora
    of tools available. Each one of them has its pros and cons, and we have to choose
    one that is suitable for our needs. JHipster currently provides sub-generators
    to create configuration files to containerize, deploy, and manage the microservices
    via the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Docker
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes (also helps to orchestrate your deployment)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenShift (also provides private cloud deployment)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rancher (also provides complete container management)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will see them in detail in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: A short introduction to Docker Compose
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Shipping code to the server is always difficult, especially when you want to
    scale it. This is mainly because we have to manually create the same environment
    and make sure the application has all the necessary connectivity (to other services)
    that is needed. This was a major pain point for teams when shipping and scaling
    their code.
  prefs: []
  type: TYPE_NORMAL
- en: Shipping code to the server is difficult.
  prefs: []
  type: TYPE_NORMAL
- en: Containers were the game-changer in this field. They helped to bundle the entire
    application along with dependencies in a shippable container, and all we need
    is to provide an environment in which these containers can run. This simplified
    the process of shipping code to the server and also among the development teams.
    This also reduced the amount of time a team spent making sure that the application
    ran seamlessly across the environment.
  prefs: []
  type: TYPE_NORMAL
- en: Containers solve the application deployment problem, but how do we scale them?
  prefs: []
  type: TYPE_NORMAL
- en: The Docker Compose tool comes to the rescue here. First, let's see what Docker
    Compose is, and then see what problems it solves.
  prefs: []
  type: TYPE_NORMAL
- en: Docker Compose is a tool that helps to define and run multi-container Docker
    applications with a single file. That is, we use a `.yaml` file to define the
    requirements and/or dependencies of the application. Then, with `docker-compose`,
    we can create newer deployments and start our applications as defined in the `docker-compose`
    file.
  prefs: []
  type: TYPE_NORMAL
- en: So, what is required in a `docker-compose` file?
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code segment is a sample `docker-compose` file that will start
    a Redis database on port `5000`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The first line of the `docker-compose` file should be the version of the `docker-compose`
    tool.
  prefs: []
  type: TYPE_NORMAL
- en: Then we need to specify all the necessary services that we need for our application
    to run. They should be defined in the `services:` section.
  prefs: []
  type: TYPE_NORMAL
- en: We can also define multiple services inside here, giving a name to each (`web`
    and `redis`).
  prefs: []
  type: TYPE_NORMAL
- en: This is followed by how to build the `service` (either via a command to build
    or referring a Dockerfile).
  prefs: []
  type: TYPE_NORMAL
- en: 'If the application needs any port access, we can configure it using `5000:5000`
    (that is internal port: external port).'
  prefs: []
  type: TYPE_NORMAL
- en: Then, we have to specify the volume information. This basically tells `docker-compose`
    to serve the files from the location specified.
  prefs: []
  type: TYPE_NORMAL
- en: Once we have specified the services required for our application, then we can
    start the application via `docker-compose`. This will start your entire application
    along with the services, and expose the `services` on the port specified.
  prefs: []
  type: TYPE_NORMAL
- en: 'With `docker-compose`, we can perform the following operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Start**: `docker-compose -f <docker_file> up`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stop**: `docker-compose -f <docker_file> down`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can also perform the following operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '**List the running services and their status**: `docker ps`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Logs**: `docker log <container_id>`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the compose file, we can add the project name, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This can be used for identifying multiple environments. With the help of this,
    we can isolate multiple environments. This helps us to handle multiple instances
    across various `dev`, `QA`, and `prod` environments.
  prefs: []
  type: TYPE_NORMAL
- en: '`Docker-compose` is itself a great tool for deploying your application along
    with all the services it needs. It provides infrastructure as a code. It is an
    excellent choice for development, QA, and other environments except for production.
    But why?'
  prefs: []
  type: TYPE_NORMAL
- en: '`Docker-compose` is really good for creating and starting your application.
    However, when you want to update an existing container there will be a definite
    downtime, since `docker-compose` will recreate the entire container (there are
    few workarounds to make this happen but still, `docker-compose` needs some improvement
    in this space.)'
  prefs: []
  type: TYPE_NORMAL
- en: Kickstarting Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'According to the Kubernetes website:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Kubernetes is an open-source system for automating deployment, scaling, and
    management of containerized applications.*'
  prefs: []
  type: TYPE_NORMAL
- en: It is a simple and powerful tool for automatic deployment, scaling, and managing
    containerized applications. It provides zero downtime when you roll out a newer
    application or update an existing application. You can automate it to scale in
    and out based on certain factors. It also provides self-healing, such that Kubernetes
    automatically detects the failing application and spins up a new instance. We
    can also define secrets and configuration that can be used across instances.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes primarily focuses on zero downtime production applications upgrades,
    and also scales them as required.
  prefs: []
  type: TYPE_NORMAL
- en: A single deployable component is called a **pod** in Kubernetes. This can be
    as simple as a running process in the container. A group of pods can be combined
    together to form a **deployment**.
  prefs: []
  type: TYPE_NORMAL
- en: Similar to `docker-compose`, we can define the applications and their required
    services in a single YAML file or multiple files (as per our convenience).
  prefs: []
  type: TYPE_NORMAL
- en: Here also, we start with an `apiVersion` in a Kubernetes deployment file.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code is a sample Kubernetes file that will start a Nginx server:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Followed by the type, which takes either a pod, deployment, namespace, ingress
    (load balancing the pods), role, and many more.
  prefs: []
  type: TYPE_NORMAL
- en: Ingress forms a layer between the services and the internet so that all the
    inbound connections are controlled or configured with the ingress controller before
    sending them to Kubernetes services on the cluster. On the other hand, the egress
    controller controls or configures services going out of the Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: This is followed by the metadata information, such as the type of environments,
    the application name (nginxsvc), and labels (Kubernetes uses this information
    to identify and segregate the pods). Kubernetes uses this metadata information
    to identify the particular pods or a group of pods, and we can manage the instances
    with this metadata. This is one of the key differences with `docker-compose`,
    where `docker-compose` doesn't have the flexibility of defining the metadata about
    the containers.
  prefs: []
  type: TYPE_NORMAL
- en: This is followed by the spec, where we define the specification of the images
    or our application. We can also define the pull strategy for our images as well
    as define the environment variables along with the exposed ports. We can define
    the resource limitations on the machine (or VM) for a particular service. They
    provide health checks, that is, each service is monitored for the health and when
    some services fail, they are immediately replaced by newer ones. They also provide
    service discovery out of the box, by assigning each pod an IP, which makes it
    easier for the services to identify and interact with them. They also provide
    a better dashboard, to visualize your architecture and the status of the application.
    You can do most of the management via this dashboard, such as checking the status,
    logs, scale up, or down the services, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Since Kubernetes provide a complete orchestration of our services with configurable
    options, it makes it really hard to set up initially, and this means it is not
    ideal for a development environment. We also need the **kubectl** CLI tool for
    management. Despite the fact that we use Docker images inside, the Docker CLI
    can't be used.
  prefs: []
  type: TYPE_NORMAL
- en: There is also **Minikube** (minified Kubernetes), which is used for developing
    and testing applications locally.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes not only takes care of containerizing your application, it also helps
    to scale, manage, and deploy your application. It orchestrates your entire application
    deployment. Additionally, it also provides service discovery and automated health
    checks.
  prefs: []
  type: TYPE_NORMAL
- en: We will focus more on the Kubernetes sub-generator in the following chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing OpenShift
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: OpenShift is a multi-cloud, open source container application platform. It is
    based on Kubernetes and used for developing, deploying, and managing applications.
    It is a common platform for developers and operations. It helps them to build,
    deploy, and manage applications consistently across hybrid cloud and multi-cloud
    infrastructures.
  prefs: []
  type: TYPE_NORMAL
- en: For developers, it provides a self-service platform in which they can provision,
    build, and deploy applications and their components. With automated workflows
    for converting your source to the image, it helps developers go from source to
    ready-to-run, dockerized images.
  prefs: []
  type: TYPE_NORMAL
- en: For operations, it provides a secure, enterprise-grade Kubernetes for policy-based
    controls and automation for application management, such as cluster services,
    scheduling, and orchestration with load balancing and auto-scaling capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: JHipster also provides OpenShift deployment files as a separate sub-generator.
    We can generate them by running `jhipster openshift` and answering the questions
    as needed. This will generate OpenShift related deployment files.
  prefs: []
  type: TYPE_NORMAL
- en: Explaining Rancher
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Rancher is a container management platform. It is also open source. It helps
    to deploy and maintain containers for any organization. Rancher is merely a deployment
    server that is installed on any Linux machine or cluster. So to use Rancher, we
    should first start the Rancher container, and this requires Docker to be available.
  prefs: []
  type: TYPE_NORMAL
- en: Once started, we can log in to Rancher and start deploying our applications.
    It also has role management. Rancher provides an option to choose between Swarm,
    Kubernetes, or Cattle (and other cluster deployment options). It also provides
    details about the infrastructure and applications that are deployed. It shows
    detailed information about the containers, registries, data pools, and other information
    (related to the container and infrastructure).
  prefs: []
  type: TYPE_NORMAL
- en: It also provides options to tweak the Kubernetes or Swarm settings as needed,
    so it makes it much easier to scale up and down. It also provides options to launch
    the entire application stack via its UI or using `docker-compose.yml` and `rancher-compose.yml`.
    It also has the capability to load the external services and use them (such as
    a load balancer).
  prefs: []
  type: TYPE_NORMAL
- en: JHipster also provides Rancher deployment files as a separate sub-generator.
    We can generate them by running `jhipster rancher` and answering the questions
    as needed. This will generate the Rancher configuration files.
  prefs: []
  type: TYPE_NORMAL
- en: Generated Docker Compose files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'By default, JHipster will generate Docker Compose files that enable us to run
    the application completely in the containerized environment, irrespective of the
    options chosen. For example, in the gateway application that we have generated,
    the following files are generated by default under `src/main/docker`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`sonar.yml`: This file creates and starts a SonarQube server'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mysql.yml`: This file creates and starts a MySQL database server and creates
    a user and schema'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`jhipster-registry.yml`: This file creates and starts a JHipster Registry service'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`app.yml`: This is the main file that creates and starts the application along
    with services such as JHipster registry and the database'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In addition to this, JHipster also creates a Dockerfile, which helps you to
    containerize the application alone.
  prefs: []
  type: TYPE_NORMAL
- en: Then we can see a folder called `central-server-config`. This will be used as
    a central configuration server for the JHipster Registry.
  prefs: []
  type: TYPE_NORMAL
- en: When the registry and the application are running in Docker, it uses `application.yml`
    from the `docker-config` folder as the central configuration server.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, when running only the registry in Docker mode, the application,
    not in Docker, will use `application.yml` from the `localhost-config` folder.
    The key difference is that the URL defining the Eureka client varies.
  prefs: []
  type: TYPE_NORMAL
- en: Let's see the Docker files that have been generated.
  prefs: []
  type: TYPE_NORMAL
- en: Walking through the generated files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's start with the `app.yml` file under `src/main/docker` inside your gateway
    application.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we saw at the beginning of the chapter, the file starts with the Docker
    version that it supports:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This is followed by the services section where we define the various services,
    applications, or components that we will kick start with this Docker file.
  prefs: []
  type: TYPE_NORMAL
- en: Under services section, we will define a name for the service, in our case we
    have used `gateway-app`, followed by the image that we want to use as a container.
    This image is generated with the help of the Docker file that we have in that
    folder.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is followed by the series of environment variables that our application
    will depend on, they include:'
  prefs: []
  type: TYPE_NORMAL
- en: '`SPRING_PROFILES_ACTIVE`: Tells the application to run in production mode and
    expose Swagger endpoints.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`EUREKA_CLIENT_SERVICE_URL_DEFAULTZONE`: Tells the application where to check
    for the JHipster Registry (which is the Eureka client that we are using. If we
    have chosen Consul here, then the application will point to the Consul URL)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SPRING_CLOUD_CONFIG_URI`: Tells the application where to look for the `config`
    service for the application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SPRING_DATASOURCE_URL`: Tells the application where to look for the data source.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`JHIPSTER_SLEEP`: This is a custom property that we have used to make sure
    that the JHipster Registry starts before the application starts up.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Finally, we specify on which port the application should run and be exposed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: We have just defined the service with the `docker-compose` file; now we have
    to specify two other services that are needed for our application to run. They
    are the database and JHipster Registry.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, we register another service called `gateway-mysql`, which creates and starts
    the MySQL server. We can define MySQL as a separate Docker Compose file and link
    them in here. So, we put an `extends` keyword followed by the `docker-compose`
    file and the service that we have to start from the specified `docker-compose`
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we input the following code for the `mysql.yml` file, shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We have again started with the version that it supports followed by the `services`
    keyword and then specify the `service` name, `gateway-mysql` that is used in the
    `app.yml` file. If you want to specify a volume for the persistent data storage
    you can uncomment the commented volumes segment. This basically maps the local
    file location to Docker's internal location so that the data is persistent even
    if the Docker image itself is replaced or updated.
  prefs: []
  type: TYPE_NORMAL
- en: This is followed by a set of environment variables, such as the username and
    the password (we have set it to empty here, but for a real production application
    it is recommended to set it to a more complex password), and then the database
    schema name.
  prefs: []
  type: TYPE_NORMAL
- en: We have also specified the command that we need to run to start the MySQL server.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then we go back to the `app.yml` file and we then define the JHipster Registry
    service. This will again extend the `jhipster-registry.yml` and `docker-compose`
    file. One more thing to note here is, even though we extend the services from
    another Docker file, we can override the environment variables that we have specified
    in the original `docker-compose` file. This comes in handy in certain cases where
    we have to kickstart our application with different or customized values. In our
    case, we have overridden the location of the Spring Cloud Config server file location
    from that of the original:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Jhipster-registry.yml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We have defined the central-config for JHipster Registry as follows. We have
    configured the secret for the JWT and the Eureka client''s URL. The JWT token
    specified is used for services to authorize and communicate between them and the
    registry:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Added to these, we also generate a `sonar.yml`, (this file is not important
    for deploying your application):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Similarly, in the microservices, that is, in our invoice and the notification
    applications, we will have similar files generated. They are the same except for
    the change in the service name.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike MySQL, MongoDB is also capable of running as a cluster with different
    nodes and configuration. We need to specify them differently here. So we will
    create have two docker-compose files. `mongodb.yml` is for starting the MongoDB
    with a single node, and the `mongodb-cluster.yml` to start the MongoDB as the
    cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Please check the database port number between the gateway and the microservice
    application. If they use the same database, there may be a clash in the port number
    since JHipster generates the same port number for both. Change it to any other
    unused port, or Docker Compose will show an error. In our case, I have changed
    it to `3307`.
  prefs: []
  type: TYPE_NORMAL
- en: Building and deploying everything to Docker locally
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are multiple ways in which we can use the `docker-compose` files based
    on our needs.
  prefs: []
  type: TYPE_NORMAL
- en: In general, when we are developing the application, we can run the application
    with the general Maven or Gradle command so that we can debug the application
    and also reload the changes faster, and start the database and JHipster registry
    with Docker.
  prefs: []
  type: TYPE_NORMAL
- en: 'Otherwise, you can start the entire application from the `app.yml` file, which
    will kickstart the database, JHipster Registry, and then the application itself.
    To do that, open your terminal or Command Prompt, go to the application folder,
    and then run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we have to first Dockerize the application by taking a production build
    of our application with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Once done, we can start the app via the `docker-compose` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '`-f` specifies the file with which `docker-compose` should start the server.
    The `-d` flag tells `docker-compose` to run everything in detached mode. This
    will start the application in Docker and expose the application on port `8080`,
    the registry server on port `8761`, and the database on port `3306`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Then we can go to the respective microservices folder and do the same, create a
    docker image with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we can start the application via `docker-compose` with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'We can check the running Docker containers with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'It should list all seven containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/823303fc-e453-42ca-b415-eb29d6ec4793.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, there are three app containers (gateway/notification, and invoice),
    and then a JHipster-Registry, followed by three database containers (two MySQL
    and one MongoDB. The order may vary).
  prefs: []
  type: TYPE_NORMAL
- en: If you are using JHipster Version 5 or above use `bootWar` instead of the `bootRepackage`
    command in Gradle.
  prefs: []
  type: TYPE_NORMAL
- en: Generating docker-compose files for microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are many `docker-compose` files and maintaining them is hard. Thankfully,
    JHipster has a `docker-compose` sub generator bundled with it. The `Docker-compose` sub
    generator helps you to organize all your application's Dockerfiles together. It
    creates a single Dockerfile that refers to the application's Dockerfiles.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s go to the base folder and create a folder and name it `docker-compose`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Once inside the `docker-compose` folder, we can run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: This will generate the Dockerfiles.
  prefs: []
  type: TYPE_NORMAL
- en: 'As usual, it will ask us a series of questions, before generating the files:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6fc3ae79-37a7-4a6c-a6a1-458d5c2f7a51.png)'
  prefs: []
  type: TYPE_IMG
- en: At first, it asks which type of application we would like to deploy. We will
    select the microservice application as an option.
  prefs: []
  type: TYPE_NORMAL
- en: This is followed by choosing the type of gateway that we would like to use;
    there are two options available, a JHipster-gateway with Zuul proxy, and the more
    exciting, Traefik gateway with Consul
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us choose JHipster-gateway with Zuul proxy:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2d028b76-22d8-4930-8ee0-f5f9f8b45bfe.png)'
  prefs: []
  type: TYPE_IMG
- en: Then, we have to select the location of the microservices gateway and applications.
    This is the main reason why we have generated the applications inside a single
    parent folder. This will help plugins and sub-generators to easily find the docker
    configuration files created. We will select the default option (../)
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a480c434-a824-4568-bcc5-cca434bbe6d5.png)'
  prefs: []
  type: TYPE_IMG
- en: After selecting the location, JHipster will search inside the given folder for
    any JHipster generated the application and list them in the next question.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our case, it lists notification, invoice, and gateway. We can choose all
    of them and hit *Enter*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9af279b6-42ad-4a37-9413-0b1590627a08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It automatically detects that we have used MongoDB and asks us the next question;
    whether we would like to have MongoDB as a cluster. We will not choose anything
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/36154e7c-2dee-4177-93c5-7e844dd8ee14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Then it asks about the console; whether we need to set up any consoles for
    the application. We will choose logs and metrics with the JHipster Console (based
    on ELK and Zipkin):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/604d8af5-db29-4b8e-923f-da698e6691c7.png)'
  prefs: []
  type: TYPE_IMG
- en: We can either opt out from the monitoring option or choose Prometheus. That
    connects with Prometheus and shows metrics only.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then JHipster asks whether you need Curator or Zipkin:'
  prefs: []
  type: TYPE_NORMAL
- en: Curator will help you to curate and manage the indices created by Elasticsearch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zipkin (as discussed in the previous chapter)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/cf0fdc3c-a344-4a4f-9b3f-5e89b59f50df.png)'
  prefs: []
  type: TYPE_IMG
- en: Since the JHipster console is chosen, it will ask for additional pieces of information
    supported by the console. They include Zipkin and Curator. We have already seen
    Zipkin. Curator, on the other hand, will help us to manage and curate the indices
    in Elasticsearch.
  prefs: []
  type: TYPE_NORMAL
- en: We will choose only Zipkin here.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/59d1b8c4-99c8-468a-b7c5-d49e46f271d9.png)'
  prefs: []
  type: TYPE_IMG
- en: We can also choose nothing here and go with the default option.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, it asks for the password for the JHipster Registry; we will go with
    the default here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0b3bd232-743e-416d-9c10-d6c2451fbfb5.png)'
  prefs: []
  type: TYPE_IMG
- en: That is it; we have just created a higher-level Dockerfile that has information
    about all the services that we need to run the application successfully.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can just run the entire suite with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: This will start the gateway, notification, invoice, and the registry, along
    with the console and all other required services.
  prefs: []
  type: TYPE_NORMAL
- en: Features of the deployed application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Thus, the deployed applications are ready to be launched. We can launch the
    JHipster Registry at `http://localhost:8761`; it will list all the registered
    applications:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3eb7cfcc-036a-43f0-9766-e232a6c9196f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Added to that, the registry also tells us the number of instances that are
    registered. Navigate to Eureka | Instances to check that. Currently, we have one
    of each instance registered:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/639db113-5f5f-4644-90e3-673bb49742ba.png)'
  prefs: []
  type: TYPE_IMG
- en: Similarly, the Gateway application will list down the microservices that are
    connected to it. Go to `http://localhost:8080`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Navigate to Administration | Gateway to see the microservices applications
    that are connected to this Gateway application:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/51b49e7e-d335-4760-9356-7aa15d0f1646.png)'
  prefs: []
  type: TYPE_IMG
- en: JHipster console demo
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: JHipster also provides a console application based on the ELK stack, which can
    be used for logs and metrics monitoring of the application. JHipster Console is
    another open source application. It is really useful and provides some nice dashboards
    to visualize the application. As with other JHipster products, it is much easier
    to get started with the JHipster Console.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s go back to our book folder, and then clone the JHipster console project
    from GitHub ([https://github.com/jhipster/jhipster-console](https://github.com/jhipster/jhipster-console)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Before we start our console, we need to make our applications log the metrics
    and log into the console. To make that happen, we need to change a few settings
    in our applications and then restart them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s go to our `application-prod.yml` file in all the applications (gateway
    and microservices application) and enable the logstash and logs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Set enabled to true in `metrics.logs.enabled` and also `logging.logstash.enabled`.
    This will push the logs to the console application. JHipster Console will collect
    this information and show it in nice-looking dashboards with the help of Kibana.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once cloned, we can go into this folder and then start the `jhipster-console`
    with the help of `docker-compose`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: That is it. Your console is running on `http://localhost:5601`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Kibana provides the following (customizable) dashboards:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/490f238b-6224-40c9-90a9-45035675d289.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Kibana also provides application-level metrics, such as JVM threads metrics
    and other details:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/53dc92f3-6f24-41cf-86b2-623c87c342ff.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Added to this, the console also has an interface where we can see the application
    logs. It shows the log of all the applications deployed. We can filter and search
    the logs with respect to the application:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a12046f7-0bda-4168-a082-5bc6b2b2918a.png)'
  prefs: []
  type: TYPE_IMG
- en: Kibana also provides a machine-learning tab where we can create a job to track
    the data and then choose any metric available to track it as a sum, count, high
    count, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Scaling up with Docker Swarm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Docker Swarm is Docker's orchestrating layer to manage the containers. It is
    a cluster management tool that focuses on creating replicas of your services,
    networks, as well as storage resources available to it and managing them.
  prefs: []
  type: TYPE_NORMAL
- en: The Docker Swarm is nothing more than a cluster of Docker nodes. They act as
    a manager or worker. One interesting feature to note is that a Docker container
    inside the Swarm can either be a manager or worker or both. This helps the swarm
    to allocate a new manager when the manager nodes go down.
  prefs: []
  type: TYPE_NORMAL
- en: At a high level, the manager nodes are responsible for cluster management tasks
    and execute containers. The workers are responsible for executing the containers
    only.
  prefs: []
  type: TYPE_NORMAL
- en: 'JHipster applications give us the flexibility to scale our entire application
    with a single command, with JHipster''s `docker-compose sub-generator`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can scale the instances, using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding command will spin another invoice instance and we can see it
    on the dashboard, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8c9ea7db-888c-4ceb-87a6-dfc146928e9c.png)'
  prefs: []
  type: TYPE_IMG
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have seen how to generate, set up, and start JHipster Registry and
    console, and, we have looked at their features. This was followed by how to scale
    the application with `docker-swarm`.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will see how to deploy the application to the Google
    Cloud using Kubernetes.
  prefs: []
  type: TYPE_NORMAL
